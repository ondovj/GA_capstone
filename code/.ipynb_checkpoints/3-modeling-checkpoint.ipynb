{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Food Serving Sizes Through Nutrition Profiles\n",
    "\n",
    "### Notebook 3 - Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Importing Packages](#Importing-Packages)\n",
    "2. [Reading Data](#Reading-Data)\n",
    "3. [Feature Engineering](#Feature-Engineering)\n",
    "4. [Preprocessing](#Preprocessing)\n",
    "5. [Modeling](#Modeling)\n",
    "    1. [Baseline Model](#Baseline-Model)\n",
    "    2. [Linear Regression](#Linear-Regression)\n",
    "    3. [Ridge Regression](#Ridge-Regression)\n",
    "    4. [LASSO Regression](#LASSO-Regression)\n",
    "    5. [Neural Network](#Neural-Network)\n",
    "6. [Model Evaluations](#Model-Evaluations)\n",
    "    1. [R<sup>2</sup> Score](#R2-Score)\n",
    "    2. [Mean Squared Error](#Mean-Squared-Error)\n",
    "    3. [Visualizations](#Visualizations)\n",
    "7. [Conclusions and Recommendations](#Conclusions-and-Recommendations)\n",
    "    1. [Conclusions](#Conclusions)\n",
    "    2. [Recommendations](#Recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general tools/visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow import set_random_seed\n",
    "import pickle\n",
    "\n",
    "# imports for NLP\n",
    "import regex as re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# imports for modeling\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, Ridge, SGDRegressor\n",
    "from sklearn.svm import SVR\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import regularizers\n",
    "\n",
    "# making the magic happen for plots\n",
    "%matplotlib inline\n",
    "\n",
    "# setting options for better viewing\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.max_colwidth\", 50)\n",
    "\n",
    "# setting global random seeds for numpy and tensorflow\n",
    "np.random.seed(42)\n",
    "set_random_seed(777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods = pd.read_csv(\"../datasets/clean_foods_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fdc_id</th>\n",
       "      <th>brand_owner</th>\n",
       "      <th>branded_food_category</th>\n",
       "      <th>description</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>serving_size</th>\n",
       "      <th>household_serving_fulltext</th>\n",
       "      <th>energy</th>\n",
       "      <th>fat_total</th>\n",
       "      <th>fat_sat</th>\n",
       "      <th>fat_trans</th>\n",
       "      <th>chol</th>\n",
       "      <th>protein</th>\n",
       "      <th>carbs</th>\n",
       "      <th>fiber</th>\n",
       "      <th>sugars</th>\n",
       "      <th>sodium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>356425</td>\n",
       "      <td>G. T. Japan, Inc.</td>\n",
       "      <td>Ice Cream &amp; Frozen Yogurt</td>\n",
       "      <td>MOCHI ICE CREAM BONBONS</td>\n",
       "      <td>ICE CREAM INGREDIENTS: MILK, CREAM, SUGAR, STR...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1 PIECE</td>\n",
       "      <td>200.0</td>\n",
       "      <td>6.25</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>35.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>356426</td>\n",
       "      <td>FRESH &amp; EASY</td>\n",
       "      <td>Ketchup, Mustard, BBQ &amp; Cheese Sauce</td>\n",
       "      <td>CHIPOTLE BARBECUE SAUCE</td>\n",
       "      <td>WATER, SUGAR, TOMATO PASTE, MOLASSES, DISTILLE...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2 Tbsp</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.84</td>\n",
       "      <td>703.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>356427</td>\n",
       "      <td>FRESH &amp; EASY</td>\n",
       "      <td>Ketchup, Mustard, BBQ &amp; Cheese Sauce</td>\n",
       "      <td>HOT &amp; SPICY BARBECUE SAUCE</td>\n",
       "      <td>SUGAR, WATER, DISTILLED VINEGAR, TOMATO PASTE,...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2 Tbsp</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.29</td>\n",
       "      <td>676.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>356428</td>\n",
       "      <td>FRESH &amp; EASY</td>\n",
       "      <td>Ketchup, Mustard, BBQ &amp; Cheese Sauce</td>\n",
       "      <td>BARBECUE SAUCE</td>\n",
       "      <td>TOMATO PUREE (WATER, TOMATO PASTE), SUGAR, DIS...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2 Tbsp</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.57</td>\n",
       "      <td>971.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>356429</td>\n",
       "      <td>FRESH &amp; EASY</td>\n",
       "      <td>Ketchup, Mustard, BBQ &amp; Cheese Sauce</td>\n",
       "      <td>BARBECUE SAUCE</td>\n",
       "      <td>SUGAR, DISTILLED VINEGAR, WATER, TOMATO PASTE,...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2 Tbsp</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.24</td>\n",
       "      <td>757.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fdc_id        brand_owner                 branded_food_category  \\\n",
       "0  356425  G. T. Japan, Inc.             Ice Cream & Frozen Yogurt   \n",
       "1  356426       FRESH & EASY  Ketchup, Mustard, BBQ & Cheese Sauce   \n",
       "2  356427       FRESH & EASY  Ketchup, Mustard, BBQ & Cheese Sauce   \n",
       "3  356428       FRESH & EASY  Ketchup, Mustard, BBQ & Cheese Sauce   \n",
       "4  356429       FRESH & EASY  Ketchup, Mustard, BBQ & Cheese Sauce   \n",
       "\n",
       "                  description  \\\n",
       "0     MOCHI ICE CREAM BONBONS   \n",
       "1     CHIPOTLE BARBECUE SAUCE   \n",
       "2  HOT & SPICY BARBECUE SAUCE   \n",
       "3              BARBECUE SAUCE   \n",
       "4              BARBECUE SAUCE   \n",
       "\n",
       "                                         ingredients  serving_size  \\\n",
       "0  ICE CREAM INGREDIENTS: MILK, CREAM, SUGAR, STR...          40.0   \n",
       "1  WATER, SUGAR, TOMATO PASTE, MOLASSES, DISTILLE...          37.0   \n",
       "2  SUGAR, WATER, DISTILLED VINEGAR, TOMATO PASTE,...          34.0   \n",
       "3  TOMATO PUREE (WATER, TOMATO PASTE), SUGAR, DIS...          35.0   \n",
       "4  SUGAR, DISTILLED VINEGAR, WATER, TOMATO PASTE,...          37.0   \n",
       "\n",
       "  household_serving_fulltext  energy  fat_total  fat_sat  fat_trans  chol  \\\n",
       "0                    1 PIECE   200.0       6.25     3.75        0.0  25.0   \n",
       "1                     2 Tbsp   162.0       0.00     0.00        0.0   0.0   \n",
       "2                     2 Tbsp   176.0       0.00     0.00        0.0   0.0   \n",
       "3                     2 Tbsp   143.0       0.00     0.00        0.0   0.0   \n",
       "4                     2 Tbsp   189.0       0.00     0.00        0.0   0.0   \n",
       "\n",
       "   protein  carbs  fiber  sugars  sodium  \n",
       "0      2.5  35.00    0.0   30.00    75.0  \n",
       "1      0.0  43.24    0.0   37.84   703.0  \n",
       "2      0.0  41.18    0.0   35.29   676.0  \n",
       "3      0.0  34.29    0.0   28.57   971.0  \n",
       "4      0.0  45.95    0.0   43.24   757.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foods.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the modeling process begins, we need to fully prepare the dataset. In the previous notebook we had seen the tailed distribution of the serving size target, so we will make a new column here to use as the target for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods[\"log_serv\"] = np.log(foods[\"serving_size\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to use the category of the food product as a feature, we will have to turn them into dummy columns first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods = pd.get_dummies(data=foods,\n",
    "                       columns=[\"branded_food_category\"],\n",
    "                       prefix=\"cat\",\n",
    "                       drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fdc_id</th>\n",
       "      <th>brand_owner</th>\n",
       "      <th>description</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>serving_size</th>\n",
       "      <th>household_serving_fulltext</th>\n",
       "      <th>energy</th>\n",
       "      <th>fat_total</th>\n",
       "      <th>fat_sat</th>\n",
       "      <th>fat_trans</th>\n",
       "      <th>chol</th>\n",
       "      <th>protein</th>\n",
       "      <th>carbs</th>\n",
       "      <th>fiber</th>\n",
       "      <th>sugars</th>\n",
       "      <th>sodium</th>\n",
       "      <th>log_serv</th>\n",
       "      <th>cat_All Noodles</th>\n",
       "      <th>cat_Bacon, Sausages &amp; Ribs</th>\n",
       "      <th>cat_Baking</th>\n",
       "      <th>cat_Baking Accessories</th>\n",
       "      <th>cat_Baking Additives &amp; Extracts</th>\n",
       "      <th>cat_Baking Decorations &amp; Dessert Toppings</th>\n",
       "      <th>cat_Baking/Cooking Mixes (Perishable)</th>\n",
       "      <th>cat_Baking/Cooking Mixes (Shelf Stable)</th>\n",
       "      <th>cat_Baking/Cooking Mixes/Supplies Variety Packs</th>\n",
       "      <th>cat_Baking/Cooking Supplies (Shelf Stable)</th>\n",
       "      <th>cat_Beef - Prepared/Processed</th>\n",
       "      <th>cat_Biscuits/Cookies (Shelf Stable)</th>\n",
       "      <th>cat_Bread &amp; Muffin Mixes</th>\n",
       "      <th>cat_Breads &amp; Buns</th>\n",
       "      <th>cat_Breakfast Drinks</th>\n",
       "      <th>cat_Breakfast Foods</th>\n",
       "      <th>cat_Breakfast Sandwiches, Biscuits &amp; Meals</th>\n",
       "      <th>cat_Butter &amp; Spread</th>\n",
       "      <th>cat_Cake, Cookie &amp; Cupcake Mixes</th>\n",
       "      <th>cat_Cakes - Sweet (Frozen)</th>\n",
       "      <th>cat_Cakes - Sweet (Shelf Stable)</th>\n",
       "      <th>cat_Cakes, Cupcakes, Snack Cakes</th>\n",
       "      <th>cat_Candy</th>\n",
       "      <th>cat_Canned &amp; Bottled Beans</th>\n",
       "      <th>cat_Canned Condensed Soup</th>\n",
       "      <th>cat_Canned Fruit</th>\n",
       "      <th>cat_Canned Meat</th>\n",
       "      <th>cat_Canned Seafood</th>\n",
       "      <th>cat_Canned Soup</th>\n",
       "      <th>cat_Canned Tuna</th>\n",
       "      <th>cat_Canned Vegetables</th>\n",
       "      <th>cat_Cereal</th>\n",
       "      <th>cat_Cereal/Muesli Bars</th>\n",
       "      <th>...</th>\n",
       "      <th>cat_Pancakes, Waffles, French Toast &amp; Crepes</th>\n",
       "      <th>cat_Pasta Dinners</th>\n",
       "      <th>cat_Pasta by Shape &amp; Type</th>\n",
       "      <th>cat_Pasta/Noodles - Not Ready to Eat (Frozen)</th>\n",
       "      <th>cat_Pastry Shells &amp; Fillings</th>\n",
       "      <th>cat_Pepperoni, Salami &amp; Cold Cuts</th>\n",
       "      <th>cat_Pickles, Olives, Peppers &amp; Relishes</th>\n",
       "      <th>cat_Pies/Pastries - Sweet (Shelf Stable)</th>\n",
       "      <th>cat_Pies/Pastries/Pizzas/Quiches - Savoury (Frozen)</th>\n",
       "      <th>cat_Pizza</th>\n",
       "      <th>cat_Pizza Mixes &amp; Other Dry Dinners</th>\n",
       "      <th>cat_Plant Based Milk</th>\n",
       "      <th>cat_Plant Based Water</th>\n",
       "      <th>cat_Popcorn (Shelf Stable)</th>\n",
       "      <th>cat_Popcorn, Peanuts, Seeds &amp; Related Snacks</th>\n",
       "      <th>cat_Pork Sausages - Prepared/Processed</th>\n",
       "      <th>cat_Poultry, Chicken &amp; Turkey</th>\n",
       "      <th>cat_Powdered Drinks</th>\n",
       "      <th>cat_Pre-Packaged Fruit &amp; Vegetables</th>\n",
       "      <th>cat_Prepared Pasta &amp; Pizza Sauces</th>\n",
       "      <th>cat_Prepared Subs &amp; Sandwiches</th>\n",
       "      <th>cat_Prepared Wraps and Burittos</th>\n",
       "      <th>cat_Processed Cheese &amp; Cheese Novelties</th>\n",
       "      <th>cat_Puddings &amp; Custards</th>\n",
       "      <th>cat_Rice</th>\n",
       "      <th>cat_Salad Dressing &amp; Mayonnaise</th>\n",
       "      <th>cat_Sausages, Hotdogs &amp; Brats</th>\n",
       "      <th>cat_Seasoning Mixes, Salts, Marinades &amp; Tenderizers</th>\n",
       "      <th>cat_Snack, Energy &amp; Granola Bars</th>\n",
       "      <th>cat_Soda</th>\n",
       "      <th>cat_Soups - Prepared (Shelf Stable)</th>\n",
       "      <th>cat_Specialty Formula Supplements</th>\n",
       "      <th>cat_Sport Drinks</th>\n",
       "      <th>cat_Stuffing</th>\n",
       "      <th>cat_Sushi</th>\n",
       "      <th>cat_Syrups &amp; Molasses</th>\n",
       "      <th>cat_Tea Bags</th>\n",
       "      <th>cat_Tomatoes</th>\n",
       "      <th>cat_Vegetable &amp; Cooking Oils</th>\n",
       "      <th>cat_Vegetable Based Products / Meals - Not Ready to Eat (Frozen)</th>\n",
       "      <th>cat_Vegetable and Lentil Mixes</th>\n",
       "      <th>cat_Vegetables - Prepared/Processed (Frozen)</th>\n",
       "      <th>cat_Vegetables - Prepared/Processed (Shelf Stable)</th>\n",
       "      <th>cat_Vegetarian Frozen Meats</th>\n",
       "      <th>cat_Vitamins</th>\n",
       "      <th>cat_Water</th>\n",
       "      <th>cat_Weight Control</th>\n",
       "      <th>cat_Wholesome Snacks</th>\n",
       "      <th>cat_Yogurt</th>\n",
       "      <th>cat_Yogurt/Yogurt Substitutes (Perishable)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>356425</td>\n",
       "      <td>G. T. Japan, Inc.</td>\n",
       "      <td>MOCHI ICE CREAM BONBONS</td>\n",
       "      <td>ICE CREAM INGREDIENTS: MILK, CREAM, SUGAR, STR...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1 PIECE</td>\n",
       "      <td>200.0</td>\n",
       "      <td>6.25</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>35.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>75.0</td>\n",
       "      <td>3.688879</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>356426</td>\n",
       "      <td>FRESH &amp; EASY</td>\n",
       "      <td>CHIPOTLE BARBECUE SAUCE</td>\n",
       "      <td>WATER, SUGAR, TOMATO PASTE, MOLASSES, DISTILLE...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2 Tbsp</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.84</td>\n",
       "      <td>703.0</td>\n",
       "      <td>3.610918</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>356427</td>\n",
       "      <td>FRESH &amp; EASY</td>\n",
       "      <td>HOT &amp; SPICY BARBECUE SAUCE</td>\n",
       "      <td>SUGAR, WATER, DISTILLED VINEGAR, TOMATO PASTE,...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2 Tbsp</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.29</td>\n",
       "      <td>676.0</td>\n",
       "      <td>3.526361</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>356428</td>\n",
       "      <td>FRESH &amp; EASY</td>\n",
       "      <td>BARBECUE SAUCE</td>\n",
       "      <td>TOMATO PUREE (WATER, TOMATO PASTE), SUGAR, DIS...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2 Tbsp</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.57</td>\n",
       "      <td>971.0</td>\n",
       "      <td>3.555348</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>356429</td>\n",
       "      <td>FRESH &amp; EASY</td>\n",
       "      <td>BARBECUE SAUCE</td>\n",
       "      <td>SUGAR, DISTILLED VINEGAR, WATER, TOMATO PASTE,...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2 Tbsp</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.24</td>\n",
       "      <td>757.0</td>\n",
       "      <td>3.610918</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fdc_id        brand_owner                 description  \\\n",
       "0  356425  G. T. Japan, Inc.     MOCHI ICE CREAM BONBONS   \n",
       "1  356426       FRESH & EASY     CHIPOTLE BARBECUE SAUCE   \n",
       "2  356427       FRESH & EASY  HOT & SPICY BARBECUE SAUCE   \n",
       "3  356428       FRESH & EASY              BARBECUE SAUCE   \n",
       "4  356429       FRESH & EASY              BARBECUE SAUCE   \n",
       "\n",
       "                                         ingredients  serving_size  \\\n",
       "0  ICE CREAM INGREDIENTS: MILK, CREAM, SUGAR, STR...          40.0   \n",
       "1  WATER, SUGAR, TOMATO PASTE, MOLASSES, DISTILLE...          37.0   \n",
       "2  SUGAR, WATER, DISTILLED VINEGAR, TOMATO PASTE,...          34.0   \n",
       "3  TOMATO PUREE (WATER, TOMATO PASTE), SUGAR, DIS...          35.0   \n",
       "4  SUGAR, DISTILLED VINEGAR, WATER, TOMATO PASTE,...          37.0   \n",
       "\n",
       "  household_serving_fulltext  energy  fat_total  fat_sat  fat_trans  chol  \\\n",
       "0                    1 PIECE   200.0       6.25     3.75        0.0  25.0   \n",
       "1                     2 Tbsp   162.0       0.00     0.00        0.0   0.0   \n",
       "2                     2 Tbsp   176.0       0.00     0.00        0.0   0.0   \n",
       "3                     2 Tbsp   143.0       0.00     0.00        0.0   0.0   \n",
       "4                     2 Tbsp   189.0       0.00     0.00        0.0   0.0   \n",
       "\n",
       "   protein  carbs  fiber  sugars  sodium  log_serv  cat_All Noodles  \\\n",
       "0      2.5  35.00    0.0   30.00    75.0  3.688879                0   \n",
       "1      0.0  43.24    0.0   37.84   703.0  3.610918                0   \n",
       "2      0.0  41.18    0.0   35.29   676.0  3.526361                0   \n",
       "3      0.0  34.29    0.0   28.57   971.0  3.555348                0   \n",
       "4      0.0  45.95    0.0   43.24   757.0  3.610918                0   \n",
       "\n",
       "   cat_Bacon, Sausages & Ribs  cat_Baking  cat_Baking Accessories  \\\n",
       "0                           0           0                       0   \n",
       "1                           0           0                       0   \n",
       "2                           0           0                       0   \n",
       "3                           0           0                       0   \n",
       "4                           0           0                       0   \n",
       "\n",
       "   cat_Baking Additives & Extracts  cat_Baking Decorations & Dessert Toppings  \\\n",
       "0                                0                                          0   \n",
       "1                                0                                          0   \n",
       "2                                0                                          0   \n",
       "3                                0                                          0   \n",
       "4                                0                                          0   \n",
       "\n",
       "   cat_Baking/Cooking Mixes (Perishable)  \\\n",
       "0                                      0   \n",
       "1                                      0   \n",
       "2                                      0   \n",
       "3                                      0   \n",
       "4                                      0   \n",
       "\n",
       "   cat_Baking/Cooking Mixes (Shelf Stable)  \\\n",
       "0                                        0   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "\n",
       "   cat_Baking/Cooking Mixes/Supplies Variety Packs  \\\n",
       "0                                                0   \n",
       "1                                                0   \n",
       "2                                                0   \n",
       "3                                                0   \n",
       "4                                                0   \n",
       "\n",
       "   cat_Baking/Cooking Supplies (Shelf Stable)  cat_Beef - Prepared/Processed  \\\n",
       "0                                           0                              0   \n",
       "1                                           0                              0   \n",
       "2                                           0                              0   \n",
       "3                                           0                              0   \n",
       "4                                           0                              0   \n",
       "\n",
       "   cat_Biscuits/Cookies (Shelf Stable)  cat_Bread & Muffin Mixes  \\\n",
       "0                                    0                         0   \n",
       "1                                    0                         0   \n",
       "2                                    0                         0   \n",
       "3                                    0                         0   \n",
       "4                                    0                         0   \n",
       "\n",
       "   cat_Breads & Buns  cat_Breakfast Drinks  cat_Breakfast Foods  \\\n",
       "0                  0                     0                    0   \n",
       "1                  0                     0                    0   \n",
       "2                  0                     0                    0   \n",
       "3                  0                     0                    0   \n",
       "4                  0                     0                    0   \n",
       "\n",
       "   cat_Breakfast Sandwiches, Biscuits & Meals  cat_Butter & Spread  \\\n",
       "0                                           0                    0   \n",
       "1                                           0                    0   \n",
       "2                                           0                    0   \n",
       "3                                           0                    0   \n",
       "4                                           0                    0   \n",
       "\n",
       "   cat_Cake, Cookie & Cupcake Mixes  cat_Cakes - Sweet (Frozen)  \\\n",
       "0                                 0                           0   \n",
       "1                                 0                           0   \n",
       "2                                 0                           0   \n",
       "3                                 0                           0   \n",
       "4                                 0                           0   \n",
       "\n",
       "   cat_Cakes - Sweet (Shelf Stable)  cat_Cakes, Cupcakes, Snack Cakes  \\\n",
       "0                                 0                                 0   \n",
       "1                                 0                                 0   \n",
       "2                                 0                                 0   \n",
       "3                                 0                                 0   \n",
       "4                                 0                                 0   \n",
       "\n",
       "   cat_Candy  cat_Canned & Bottled Beans  cat_Canned Condensed Soup  \\\n",
       "0          0                           0                          0   \n",
       "1          0                           0                          0   \n",
       "2          0                           0                          0   \n",
       "3          0                           0                          0   \n",
       "4          0                           0                          0   \n",
       "\n",
       "   cat_Canned Fruit  cat_Canned Meat  cat_Canned Seafood  cat_Canned Soup  \\\n",
       "0                 0                0                   0                0   \n",
       "1                 0                0                   0                0   \n",
       "2                 0                0                   0                0   \n",
       "3                 0                0                   0                0   \n",
       "4                 0                0                   0                0   \n",
       "\n",
       "   cat_Canned Tuna  cat_Canned Vegetables  cat_Cereal  cat_Cereal/Muesli Bars  \\\n",
       "0                0                      0           0                       0   \n",
       "1                0                      0           0                       0   \n",
       "2                0                      0           0                       0   \n",
       "3                0                      0           0                       0   \n",
       "4                0                      0           0                       0   \n",
       "\n",
       "   ...  cat_Pancakes, Waffles, French Toast & Crepes  cat_Pasta Dinners  \\\n",
       "0  ...                                             0                  0   \n",
       "1  ...                                             0                  0   \n",
       "2  ...                                             0                  0   \n",
       "3  ...                                             0                  0   \n",
       "4  ...                                             0                  0   \n",
       "\n",
       "   cat_Pasta by Shape & Type  cat_Pasta/Noodles - Not Ready to Eat (Frozen)  \\\n",
       "0                          0                                              0   \n",
       "1                          0                                              0   \n",
       "2                          0                                              0   \n",
       "3                          0                                              0   \n",
       "4                          0                                              0   \n",
       "\n",
       "   cat_Pastry Shells & Fillings  cat_Pepperoni, Salami & Cold Cuts  \\\n",
       "0                             0                                  0   \n",
       "1                             0                                  0   \n",
       "2                             0                                  0   \n",
       "3                             0                                  0   \n",
       "4                             0                                  0   \n",
       "\n",
       "   cat_Pickles, Olives, Peppers & Relishes  \\\n",
       "0                                        0   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "\n",
       "   cat_Pies/Pastries - Sweet (Shelf Stable)  \\\n",
       "0                                         0   \n",
       "1                                         0   \n",
       "2                                         0   \n",
       "3                                         0   \n",
       "4                                         0   \n",
       "\n",
       "   cat_Pies/Pastries/Pizzas/Quiches - Savoury (Frozen)  cat_Pizza  \\\n",
       "0                                                  0            0   \n",
       "1                                                  0            0   \n",
       "2                                                  0            0   \n",
       "3                                                  0            0   \n",
       "4                                                  0            0   \n",
       "\n",
       "   cat_Pizza Mixes & Other Dry Dinners  cat_Plant Based Milk  \\\n",
       "0                                    0                     0   \n",
       "1                                    0                     0   \n",
       "2                                    0                     0   \n",
       "3                                    0                     0   \n",
       "4                                    0                     0   \n",
       "\n",
       "   cat_Plant Based Water  cat_Popcorn (Shelf Stable)  \\\n",
       "0                      0                           0   \n",
       "1                      0                           0   \n",
       "2                      0                           0   \n",
       "3                      0                           0   \n",
       "4                      0                           0   \n",
       "\n",
       "   cat_Popcorn, Peanuts, Seeds & Related Snacks  \\\n",
       "0                                             0   \n",
       "1                                             0   \n",
       "2                                             0   \n",
       "3                                             0   \n",
       "4                                             0   \n",
       "\n",
       "   cat_Pork Sausages - Prepared/Processed  cat_Poultry, Chicken & Turkey  \\\n",
       "0                                       0                              0   \n",
       "1                                       0                              0   \n",
       "2                                       0                              0   \n",
       "3                                       0                              0   \n",
       "4                                       0                              0   \n",
       "\n",
       "   cat_Powdered Drinks  cat_Pre-Packaged Fruit & Vegetables  \\\n",
       "0                    0                                    0   \n",
       "1                    0                                    0   \n",
       "2                    0                                    0   \n",
       "3                    0                                    0   \n",
       "4                    0                                    0   \n",
       "\n",
       "   cat_Prepared Pasta & Pizza Sauces  cat_Prepared Subs & Sandwiches  \\\n",
       "0                                  0                               0   \n",
       "1                                  0                               0   \n",
       "2                                  0                               0   \n",
       "3                                  0                               0   \n",
       "4                                  0                               0   \n",
       "\n",
       "   cat_Prepared Wraps and Burittos  cat_Processed Cheese & Cheese Novelties  \\\n",
       "0                                0                                        0   \n",
       "1                                0                                        0   \n",
       "2                                0                                        0   \n",
       "3                                0                                        0   \n",
       "4                                0                                        0   \n",
       "\n",
       "   cat_Puddings & Custards  cat_Rice  cat_Salad Dressing & Mayonnaise  \\\n",
       "0                        0         0                                0   \n",
       "1                        0         0                                0   \n",
       "2                        0         0                                0   \n",
       "3                        0         0                                0   \n",
       "4                        0         0                                0   \n",
       "\n",
       "   cat_Sausages, Hotdogs & Brats  \\\n",
       "0                              0   \n",
       "1                              0   \n",
       "2                              0   \n",
       "3                              0   \n",
       "4                              0   \n",
       "\n",
       "   cat_Seasoning Mixes, Salts, Marinades & Tenderizers  \\\n",
       "0                                                  0     \n",
       "1                                                  0     \n",
       "2                                                  0     \n",
       "3                                                  0     \n",
       "4                                                  0     \n",
       "\n",
       "   cat_Snack, Energy & Granola Bars  cat_Soda  \\\n",
       "0                                 0         0   \n",
       "1                                 0         0   \n",
       "2                                 0         0   \n",
       "3                                 0         0   \n",
       "4                                 0         0   \n",
       "\n",
       "   cat_Soups - Prepared (Shelf Stable)  cat_Specialty Formula Supplements  \\\n",
       "0                                    0                                  0   \n",
       "1                                    0                                  0   \n",
       "2                                    0                                  0   \n",
       "3                                    0                                  0   \n",
       "4                                    0                                  0   \n",
       "\n",
       "   cat_Sport Drinks  cat_Stuffing  cat_Sushi  cat_Syrups & Molasses  \\\n",
       "0                 0             0          0                      0   \n",
       "1                 0             0          0                      0   \n",
       "2                 0             0          0                      0   \n",
       "3                 0             0          0                      0   \n",
       "4                 0             0          0                      0   \n",
       "\n",
       "   cat_Tea Bags  cat_Tomatoes  cat_Vegetable & Cooking Oils  \\\n",
       "0             0             0                             0   \n",
       "1             0             0                             0   \n",
       "2             0             0                             0   \n",
       "3             0             0                             0   \n",
       "4             0             0                             0   \n",
       "\n",
       "   cat_Vegetable Based Products / Meals - Not Ready to Eat (Frozen)  \\\n",
       "0                                                  0                  \n",
       "1                                                  0                  \n",
       "2                                                  0                  \n",
       "3                                                  0                  \n",
       "4                                                  0                  \n",
       "\n",
       "   cat_Vegetable and Lentil Mixes  \\\n",
       "0                               0   \n",
       "1                               0   \n",
       "2                               0   \n",
       "3                               0   \n",
       "4                               0   \n",
       "\n",
       "   cat_Vegetables - Prepared/Processed (Frozen)  \\\n",
       "0                                             0   \n",
       "1                                             0   \n",
       "2                                             0   \n",
       "3                                             0   \n",
       "4                                             0   \n",
       "\n",
       "   cat_Vegetables - Prepared/Processed (Shelf Stable)  \\\n",
       "0                                                  0    \n",
       "1                                                  0    \n",
       "2                                                  0    \n",
       "3                                                  0    \n",
       "4                                                  0    \n",
       "\n",
       "   cat_Vegetarian Frozen Meats  cat_Vitamins  cat_Water  cat_Weight Control  \\\n",
       "0                            0             0          0                   0   \n",
       "1                            0             0          0                   0   \n",
       "2                            0             0          0                   0   \n",
       "3                            0             0          0                   0   \n",
       "4                            0             0          0                   0   \n",
       "\n",
       "   cat_Wholesome Snacks  cat_Yogurt  \\\n",
       "0                     0           0   \n",
       "1                     0           0   \n",
       "2                     0           0   \n",
       "3                     0           0   \n",
       "4                     0           0   \n",
       "\n",
       "   cat_Yogurt/Yogurt Substitutes (Perishable)  \n",
       "0                                           0  \n",
       "1                                           0  \n",
       "2                                           0  \n",
       "3                                           0  \n",
       "4                                           0  \n",
       "\n",
       "[5 rows x 188 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for new cols\n",
    "foods.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our preprocessing steps here are to split our dataset into the X features and y target, and then scale the features so they can be flexibly used across different model types. The predicting features are going to include the full nutritional profile (minus the serving size), and the branded food category. We do not need the ID column since it should not be indicative of the food or serving size. The brand owner could potentially have an impact on serving size, as certain companies may tend to have larger or smaller serving sizes in general, though with\n",
    "## HOW MANY BRANDS ARE THERE???\n",
    "different brand owners, utilizing this as a modeling feature will have to be set aside for the scope of this current project. The description column is most likely not going to help, as simple prducts such as beans or vegetables will probably have very similar descriptions, and as the foods get more complicated, the descriptions will begin to vary more and more. Again, there are over \n",
    "## HOW MANY DESCRIPTIOSNS ARE THERE??\n",
    "so it would be difficult to use this as a modeling feature. The ingredients columnshows the highest promise for being useful in the modleing process, but due to time and computing restrictions, it is not going to be used at this time. The household serving size, as with the description column, can vary so much between foods, and are not necessarily standardized, so its usefulness is most likely quite low. The final two columns to be dropped are the serving size and logged serving size, which are the targets, so they should not be part of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting X and y vars\n",
    "X = foods.drop(columns=[\"fdc_id\", \n",
    "                        \"brand_owner\", \n",
    "                        \"description\", \n",
    "                        \"ingredients\", \n",
    "                        \"household_serving_fulltext\",\n",
    "                        \"serving_size\",\n",
    "                       \"log_serv\"])\n",
    "y = foods[\"log_serv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data to train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# instantiating scaler\n",
    "ss = StandardScaler()\n",
    "\n",
    "# scaling X data\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data has been fully prepared, we can begin the modeling process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a way of predicting serving size without using any machine learning, by simply using the mean of the target. For this model, we will measure the MSE, and will use the default scoring of R<sup>2</sup> for the remainder of the models. Both metrics will be evaluated for all models after the modeling is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Train MSE Score for our Base Model is: 3685.336822662155\n",
      "Our Test MSE Score for our Base Model is: 3833.116046199187\n"
     ]
    }
   ],
   "source": [
    "# building a base model to compare results against\n",
    "# using code from Boom's Local Session\n",
    "\n",
    "# Instantiate: creates a dummy regression that always predicts the mean of the target\n",
    "base_mean = DummyRegressor(strategy='mean')\n",
    "\n",
    "# Fit the \"model\"\n",
    "base_mean_model = base_mean.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions for our testing set (not kaggle testing set)\n",
    "y_hat_base_train = base_mean.predict(X_train)\n",
    "y_hat_base_test = base_mean.predict(X_test)\n",
    "\n",
    "# Get R2\n",
    "print(\"Our Train MSE Score for our Base Model is:\", metrics.mean_squared_error(np.exp(y_train),np.exp(y_hat_base_train)))\n",
    "print(\"Our Test MSE Score for our Base Model is:\",  metrics.mean_squared_error(np.exp(y_test),np.exp(y_hat_base_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The help find the best possible model parameters, we should build a function to perform gridsearches for us. We can then implement this function on any model type and set of parameters to optimize each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bringing in func from Reddit NLP project\n",
    "def grid_searcher(pipe, params):\n",
    "    gs = GridSearchCV(estimator=pipe, param_grid=params, cv=3, verbose=1, n_jobs=3)\n",
    "    gs.fit(X_train_sc, y_train)\n",
    "    print(f'CrossVal Score: {gs.best_score_}')\n",
    "    print(f'Training Score: {gs.score(X_train_sc, y_train)}')\n",
    "    print(f'Testing Score: {gs.score(X_test_sc, y_test)}')\n",
    "    print(gs.best_params_)\n",
    "    return gs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start our search for the best model with a simple OLS, or ordinary least squares model. As linear regression is a very simple model, there is really no hyperparameter searching that needs to be performed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression()\n",
    "linreg_model = linreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train R2 score is: 0.7353463856717573.\n",
      "The test R2 score is: 0.7406407151042635.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The train R2 score is: {linreg_model.score(X_train, y_train)}.\")\n",
    "print(f\"The test R2 score is: {linreg_model.score(X_test, y_test)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This basic linear regression model is not scoring very high, although it is also showing a fairly low variance. Since we did see some multicolinearity in a few of the features during the EDA, it may be worth looking at a LASSO or ridge regression for some improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the `LassoCV` model already iterates through a list of 100 alphas, we do not need to run the gridsearching function on it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jondov/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lasso = LassoCV()\n",
    "lasso_model = lasso.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train R2 score is: 0.7351460362337019.\n",
      "The test R2 score is: 0.7403776480182412.\n"
     ]
    }
   ],
   "source": [
    "train_r2 = lasso_model.score(X_train_sc, y_train)\n",
    "test_r2 = lasso_model.score(X_test_sc, y_test)\n",
    "\n",
    "print(f\"The train R2 score is: {train_r2}.\")\n",
    "print(f\"The test R2 score is: {test_r2}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While There is also a `RidgeCV` model that will test different alpha values and cross-validate, it only tests three values, which may not truly be optimizing that hyperparameter. We will employ the custom gridsearching function to expand on these values, and be able to hone in on a more precise alpha value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_pipe = Pipeline([(\"ridge\", Ridge())])\n",
    "\n",
    "ridge_params = {\n",
    "    \"ridge__alpha\": [11, 12, 13]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   9 out of   9 | elapsed:    9.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossVal Score: 0.7338202830606281\n",
      "Training Score: 0.7353441884095184\n",
      "Testing Score: 0.7406257916854004\n",
      "{'ridge__alpha': 12}\n"
     ]
    }
   ],
   "source": [
    "ridge_model = grid_searcher(ridge_pipe, ridge_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neither of these regularization methods had any large impact on the R<sup>2</sup> scores. These model are typically most helpful to regularize overfit linear regressions, and as our initial model was not very overfit, they may not just not be enough of an improvement. We may need to utilize a more advanced regression method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As using a Feed Forward Neural Network was showing promise as the best model type to use, we should have a way of effectively optimizing it. While a Keras Sequential model cannot be passed through Scikit-learn's `GridSearchCV`, we can make our own custom function to essentially perform the same type of task. To that end, the following functions were created, which were adapted from code written by Mahdi Shadkam-Farrokhi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first function to be made is for establishing the permutations of parameters. This fucntion will take in a dictionary of all the layer parameters, and unpacks each combination into a distinct set of single parameters that a model can be built on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutate_params(grid_params):\n",
    "    # returns a list of all combinations of unique parameters from the given dictionary\n",
    "    out = [{}]\n",
    "    for param_name, param_list in grid_params.items():\n",
    "        if len(param_list) == 1:\n",
    "            for item in out:\n",
    "                item[param_name] = param_list[0]\n",
    "        else:\n",
    "            temp_out = []\n",
    "            for param_val in param_list:\n",
    "                for item in out:\n",
    "                    cloned_item = item.copy()\n",
    "                    cloned_item[param_name] = param_val\n",
    "                    temp_out.append(cloned_item)\n",
    "            out = temp_out\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next piece is to take a dictionary of parameters and build a functioning model out of it. We will make a model building fucntion to perfrom this action. It will take our train/test split data, and a dictionary of the parameters that has the specified keys. The function will reach into each of the keys for the appropriate attribute, and then apply that to the corresponding layer. To increase flexibility, there will be default settings for each of the parameters, so that the dictioanry does not have to contain entries for everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(params_dict, X_train, X_test, y_train, y_test):\n",
    "    # defining params\n",
    "    first_layer_nodes = params_dict.get(\"first_layer_nodes\") or 16            # default low nodes\n",
    "    first_dropout_rate = params_dict.get(\"first_dropout_rate\") or 0.0         # default no dropout\n",
    "    \n",
    "    second_layer_nodes = params_dict.get(\"second_layer_nodes\") or 16          # default low nodes\n",
    "    second_dropout_rate = params_dict.get(\"second_dropout_rate\") or 0.0       # default no dropout\n",
    "    \n",
    "    third_layer_nodes = params_dict.get(\"third_layer_nodes\") or 16            # default low nodes\n",
    "    third_dropout_rate = params_dict.get(\"third_dropout_rate\") or 0.0         # default no dropout  \n",
    "    \n",
    "    reg = params_dict.get(\"reg\") or 0                                         # default no reg\n",
    "    \n",
    "    epochs = params_dict.get(\"epochs\") or 10                                  # default low epochs\n",
    "    batch_size = params_dict.get(\"batch_size\") or 1024                        # default large batch\n",
    "    early_stop = params_dict.get(\"early_stop\") or EarlyStopping(monitor=\"val_loss\",\n",
    "                                                                min_delta=0.000000001,  # small delta\n",
    "                                                                patience=100)           # large patience\n",
    "    \n",
    "    # instantiating model\n",
    "    model = Sequential()\n",
    "\n",
    "    # adding layers according to inputs\n",
    "    # first layer(s)\n",
    "    model.add(Dense(first_layer_nodes,\n",
    "                   activation=\"relu\",\n",
    "                   input_shape=(X_train.shape[1],),\n",
    "                   kernel_regularizer=regularizers.l2(reg)))\n",
    "    model.add(Dropout(first_dropout_rate))\n",
    "    \n",
    "    # second layer(s)\n",
    "    model.add(Dense(second_layer_nodes,\n",
    "                    activation=\"relu\",\n",
    "                    kernel_regularizer=regularizers.l2(reg)))\n",
    "    model.add(Dropout(second_dropout_rate))\n",
    "    \n",
    "    # third layer(s)\n",
    "    model.add(Dense(third_layer_nodes,\n",
    "                    activation=\"relu\",\n",
    "                    kernel_regularizer=regularizers.l2(reg)))\n",
    "    model.add(Dropout(third_dropout_rate))\n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    # compiling model\n",
    "    model.compile(loss=\"mean_squared_error\",\n",
    "             optimizer=\"adam\")\n",
    "    \n",
    "    # fitting model according to inputs\n",
    "    history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_data=(X_test, y_test),\n",
    "                       callbacks=[early_stop])\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final piece is to combine the two above functions into one function that will take and X and y, along with the parameter dictionary, and do the rest of the work for us. This function performs a train/test split, scales the data, and the runs the data through each of the models within the parameter dictionary. Each iteration will check the determined metric, and updates it if it has been improved. At the end of the function, the model that gave the best score for the metric is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_grid_search(\n",
    "    X,\n",
    "    y,\n",
    "    grid_params,\n",
    "    random_state=42\n",
    "):\n",
    "    ### this will make a series of FFNN models \n",
    "    ### and return the one with the best score as set below\n",
    "    ### currently set to test r2 score\n",
    "    \n",
    "    # list of all parameter combinations\n",
    "    all_params = permutate_params(grid_params)\n",
    "    \n",
    "    # creating vars with to update each iter\n",
    "    best_model = None\n",
    "    best_score = 0.0 \n",
    "    best_params = None\n",
    "    best_history = None\n",
    "    \n",
    "    # train/test split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state)\n",
    "    \n",
    "    # scaling data\n",
    "    ss = StandardScaler()\n",
    "    X_train_sc = ss.fit_transform(X_train)\n",
    "    X_test_sc = ss.transform(X_test)\n",
    "    \n",
    "    # looping through the unpacked parameter list\n",
    "    for i, params in enumerate(all_params):\n",
    "        \n",
    "        # keeping track of which model we're running\n",
    "        print(f\"Building model {i + 1} of {len(all_params)}\")\n",
    "        \n",
    "        # bulding the model\n",
    "        model, history = build_model(\n",
    "            params_dict = params,\n",
    "            X_train = X_train_sc, \n",
    "            X_test = X_test_sc, \n",
    "            y_train = y_train, \n",
    "            y_test = y_test\n",
    "        )\n",
    "        \n",
    "        # making preds and scoring\n",
    "        test_preds = model.predict(X_test_sc)\n",
    "        score = metrics.r2_score(y_test, test_preds)\n",
    "        \n",
    "        # checking if the score beats the current best\n",
    "        # updates vars if true\n",
    "        if score > best_score:\n",
    "            print(\"***Good R2 found: {:.2%}***\".format(score))\n",
    "            best_score = score\n",
    "            best_model = model\n",
    "            best_params = params\n",
    "            best_history = history\n",
    "    \n",
    "    # loop is done, return the best model\n",
    "    return {\n",
    "        \"best_model\"   : best_model,\n",
    "        \"best_score\"   : best_score,\n",
    "        \"best_params\"  : best_params,\n",
    "        \"best_history\" : best_history,\n",
    "        \"test_preds\"   : test_preds\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our functions built, we can run the search. We will start with finding the best number of nodes out of three hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "###     DO NOT RUN     ###\n",
    "###   W/O NEW PARAMS   ###\n",
    "\n",
    "# # setting params\n",
    "# node_params = {\n",
    "#     \"first_layer_nodes\": [256, 128, 64],\n",
    "#     \"second_layer_nodes\": [128, 64, 32],\n",
    "#     \"third_layer_nodes\": [64, 32, 16],\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###   DO NOT RE-RUN    ###\n",
    "###   W/O NEW PARAMS   ###\n",
    "\n",
    "# best_model_dict = nn_grid_search(X, y, node_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the grid search has completed, we have a list of dictionaries that holds the model that gave use the highest R<sup>2</sup> score, along with the parameters of that model, the score, and the history.\n",
    "\n",
    "In order to not have to run this cell multiple times, but be able to keep the model object, we are going to pickle the result. This process will store the completed model as its specific byte stream, which can then be loaded back exactly as it was, without needing to fit each of the models over again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "###   DO NOT RE-RUN    ###\n",
    "###   W/O ABOVE CELL   ###\n",
    "\n",
    "# # pickling tutorial found on https://www.datacamp.com/community/tutorials/pickle-python-tutorial\n",
    "\n",
    "# # making new file\n",
    "# outfile = open(\"nn_gs_pickle\", \"wb\")\n",
    "\n",
    "# # dumping model to pickle\n",
    "# pickle.dump(best_model_dict, outfile)\n",
    "\n",
    "# # closing new file\n",
    "# outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jondov/anaconda3/envs/dsi/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/jondov/anaconda3/envs/dsi/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# opening pickle file\n",
    "infile = open(\"nn_gs_pickle\", \"rb\")\n",
    "\n",
    "# unpickling back into model object\n",
    "best_model_dict = pickle.load(infile)\n",
    "\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_model': <keras.engine.sequential.Sequential at 0x1a2c1dc0d0>,\n",
       " 'best_score': 0.8712777377952519,\n",
       " 'best_params': {'first_layer_nodes': 256,\n",
       "  'second_layer_nodes': 128,\n",
       "  'third_layer_nodes': 64},\n",
       " 'best_history': <keras.callbacks.History at 0x1a2e6bb850>,\n",
       " 'test_preds': array([[5.497277 ],\n",
       "        [4.41725  ],\n",
       "        [3.7483513],\n",
       "        ...,\n",
       "        [5.102507 ],\n",
       "        [4.7589536],\n",
       "        [3.4706845]], dtype=float32)}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train R2 score is: 0.8742272462040366.\n",
      "The test R2 score is: 0.8712777377952519.\n"
     ]
    }
   ],
   "source": [
    "# making predictions\n",
    "nn_train_preds = best_model_dict[\"best_model\"].predict(X_train_sc)\n",
    "nn_test_preds = best_model_dict[\"best_model\"].predict(X_test_sc)\n",
    "\n",
    "print(f\"The train R2 score is: {metrics.r2_score(y_train, nn_train_preds)}.\")\n",
    "print(f\"The test R2 score is: {metrics.r2_score(y_test, nn_test_preds)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now take the model that had the best promise, and use those parameters in a new model to find the best amount of epochs for it. After some trials, 75 epochs seemed to be the best number to use, though we were left with some slight overfitting, so an additional search will be performed on using different regularization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_layer_nodes': 256, 'second_layer_nodes': 128, 'third_layer_nodes': 64}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pulling up best params\n",
    "best_model_dict[\"best_params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "###     DO NOT RUN     ###\n",
    "###   W/O NEW PARAMS   ###\n",
    "\n",
    "# # making new param dict with regularization\n",
    "# pdict = {\n",
    "#     \"first_layer_nodes\": [256],\n",
    "#     \"first_dropout_rate\": [0, 0.5],\n",
    "#     \"second_layer_nodes\": [128],\n",
    "#     \"second_dropout_rate\": [0, 0.5],\n",
    "#     \"third_layer_nodes\": [64],\n",
    "#     \"third_dropout_rate\": [0, 0.5],\n",
    "#     \"reg\": [0.001, 0.01],\n",
    "#     \"epochs\": [75],\n",
    "#     \"early_stop\": [EarlyStopping(monitor=\"val_loss\",\n",
    "#                                 min_delta=0.0001,\n",
    "#                                 patience=7)]         \n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model 1 of 16\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/75\n",
      "141859/141859 [==============================] - 4s 26us/step - loss: 1.6192 - val_loss: 0.6196\n",
      "Epoch 2/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.5748 - val_loss: 0.5366\n",
      "Epoch 3/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.5135 - val_loss: 0.4964\n",
      "Epoch 4/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.4681 - val_loss: 0.4439\n",
      "Epoch 5/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.4302 - val_loss: 0.4137\n",
      "Epoch 6/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.3997 - val_loss: 0.3824 0s -\n",
      "Epoch 7/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3691 - val_loss: 0.3597\n",
      "Epoch 8/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.3443 - val_loss: 0.3342\n",
      "Epoch 9/75\n",
      "141859/141859 [==============================] - 4s 26us/step - loss: 0.3224 - val_loss: 0.3188\n",
      "Epoch 10/75\n",
      "141859/141859 [==============================] - 4s 26us/step - loss: 0.3030 - val_loss: 0.2965\n",
      "Epoch 11/75\n",
      "141859/141859 [==============================] - 4s 27us/step - loss: 0.2856 - val_loss: 0.2795\n",
      "Epoch 12/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2713 - val_loss: 0.2652\n",
      "Epoch 13/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2566 - val_loss: 0.2584\n",
      "Epoch 14/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2454 - val_loss: 0.2430\n",
      "Epoch 15/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2343 - val_loss: 0.2338\n",
      "Epoch 16/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2285 - val_loss: 0.2213\n",
      "Epoch 17/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2162 - val_loss: 0.2133\n",
      "Epoch 18/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2058 - val_loss: 0.2054\n",
      "Epoch 19/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.1992 - val_loss: 0.1995\n",
      "Epoch 20/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1919 - val_loss: 0.1902\n",
      "Epoch 21/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.1855 - val_loss: 0.1902\n",
      "Epoch 22/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1809 - val_loss: 0.1824\n",
      "Epoch 23/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.1759 - val_loss: 0.1762\n",
      "Epoch 24/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.1707 - val_loss: 0.1722\n",
      "Epoch 25/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1674 - val_loss: 0.1709\n",
      "Epoch 26/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.1632 - val_loss: 0.1641\n",
      "Epoch 27/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1592 - val_loss: 0.1635\n",
      "Epoch 28/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.1578 - val_loss: 0.1591\n",
      "Epoch 29/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1550 - val_loss: 0.1579\n",
      "Epoch 30/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1541 - val_loss: 0.1548\n",
      "Epoch 31/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1490 - val_loss: 0.1513\n",
      "Epoch 32/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1488 - val_loss: 0.1529\n",
      "Epoch 33/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.1462 - val_loss: 0.1475\n",
      "Epoch 34/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.1433 - val_loss: 0.1451\n",
      "Epoch 35/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1422 - val_loss: 0.1490\n",
      "Epoch 36/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1415 - val_loss: 0.1451\n",
      "Epoch 37/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1394 - val_loss: 0.1436\n",
      "Epoch 38/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1390 - val_loss: 0.1383\n",
      "Epoch 39/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1369 - val_loss: 0.1407\n",
      "Epoch 40/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.1355 - val_loss: 0.1375\n",
      "Epoch 41/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.1360 - val_loss: 0.1439\n",
      "Epoch 42/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.1342 - val_loss: 0.1374\n",
      "Epoch 43/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.1333 - val_loss: 0.1354\n",
      "Epoch 44/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1320 - val_loss: 0.1379\n",
      "Epoch 45/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.1318 - val_loss: 0.1362\n",
      "Epoch 46/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1318 - val_loss: 0.1350\n",
      "Epoch 47/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.1326 - val_loss: 0.1355\n",
      "Epoch 48/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1298 - val_loss: 0.1358\n",
      "Epoch 49/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.1294 - val_loss: 0.1312\n",
      "Epoch 50/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.1297 - val_loss: 0.1358\n",
      "Epoch 51/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.1299 - val_loss: 0.1326\n",
      "Epoch 52/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.1290 - val_loss: 0.1311\n",
      "Epoch 53/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1265 - val_loss: 0.1317\n",
      "Epoch 54/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.1256 - val_loss: 0.1316\n",
      "Epoch 55/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1265 - val_loss: 0.1325\n",
      "Epoch 56/75\n",
      "141859/141859 [==============================] - 2s 18us/step - loss: 0.1266 - val_loss: 0.1346\n",
      "Epoch 57/75\n",
      "141859/141859 [==============================] - 2s 17us/step - loss: 0.1247 - val_loss: 0.1306\n",
      "Epoch 58/75\n",
      "141859/141859 [==============================] - 2s 18us/step - loss: 0.1243 - val_loss: 0.1298\n",
      "Epoch 59/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1254 - val_loss: 0.1342\n",
      "Epoch 60/75\n",
      "141859/141859 [==============================] - 2s 17us/step - loss: 0.1243 - val_loss: 0.1290\n",
      "Epoch 61/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1240 - val_loss: 0.1272\n",
      "Epoch 62/75\n",
      "141859/141859 [==============================] - 2s 18us/step - loss: 0.1239 - val_loss: 0.1295\n",
      "Epoch 63/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1238 - val_loss: 0.1301\n",
      "Epoch 64/75\n",
      "141859/141859 [==============================] - 2s 17us/step - loss: 0.1234 - val_loss: 0.1342\n",
      "Epoch 65/75\n",
      "141859/141859 [==============================] - 2s 18us/step - loss: 0.1247 - val_loss: 0.1268\n",
      "Epoch 66/75\n",
      "141859/141859 [==============================] - 2s 17us/step - loss: 0.1233 - val_loss: 0.1305\n",
      "Epoch 67/75\n",
      "141859/141859 [==============================] - 2s 18us/step - loss: 0.1222 - val_loss: 0.1259\n",
      "Epoch 68/75\n",
      "141859/141859 [==============================] - 2s 17us/step - loss: 0.1215 - val_loss: 0.1277\n",
      "Epoch 69/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1218 - val_loss: 0.1259\n",
      "Epoch 70/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1214 - val_loss: 0.1262\n",
      "Epoch 71/75\n",
      "141859/141859 [==============================] - 2s 18us/step - loss: 0.1215 - val_loss: 0.1263\n",
      "Epoch 72/75\n",
      "141859/141859 [==============================] - 2s 18us/step - loss: 0.1205 - val_loss: 0.1258\n",
      "Epoch 73/75\n",
      "141859/141859 [==============================] - 2s 17us/step - loss: 0.1198 - val_loss: 0.1235\n",
      "Epoch 74/75\n",
      "141859/141859 [==============================] - 2s 17us/step - loss: 0.1199 - val_loss: 0.1249\n",
      "Epoch 75/75\n",
      "141859/141859 [==============================] - 2s 17us/step - loss: 0.1201 - val_loss: 0.1234\n",
      "***Good R2 found: 89.80%***\n",
      "Building model 2 of 16\n",
      "WARNING:tensorflow:From /Users/jondov/anaconda3/envs/dsi/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/75\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 2.1758 - val_loss: 0.9144\n",
      "Epoch 2/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.8766 - val_loss: 0.8618\n",
      "Epoch 3/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.7315 - val_loss: 0.8827\n",
      "Epoch 4/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.6127 - val_loss: 0.8417\n",
      "Epoch 5/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.5273 - val_loss: 0.7252\n",
      "Epoch 6/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.4708 - val_loss: 0.5930\n",
      "Epoch 7/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.4301 - val_loss: 0.5006\n",
      "Epoch 8/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.3992 - val_loss: 0.4381\n",
      "Epoch 9/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.3725 - val_loss: 0.3928\n",
      "Epoch 10/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.3507 - val_loss: 0.3479\n",
      "Epoch 11/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.3301 - val_loss: 0.3383\n",
      "Epoch 12/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.3116 - val_loss: 0.3041\n",
      "Epoch 13/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2951 - val_loss: 0.2895\n",
      "Epoch 14/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2813 - val_loss: 0.2654\n",
      "Epoch 15/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2690 - val_loss: 0.2666\n",
      "Epoch 16/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2566 - val_loss: 0.2415\n",
      "Epoch 17/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2461 - val_loss: 0.2316\n",
      "Epoch 18/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2367 - val_loss: 0.2206\n",
      "Epoch 19/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2270 - val_loss: 0.2134\n",
      "Epoch 20/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2203 - val_loss: 0.2042\n",
      "Epoch 21/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2134 - val_loss: 0.2017\n",
      "Epoch 22/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2071 - val_loss: 0.1923\n",
      "Epoch 23/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2017 - val_loss: 0.1887\n",
      "Epoch 24/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1960 - val_loss: 0.1830\n",
      "Epoch 25/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1919 - val_loss: 0.1761\n",
      "Epoch 26/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1875 - val_loss: 0.1769\n",
      "Epoch 27/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1840 - val_loss: 0.1724\n",
      "Epoch 28/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1814 - val_loss: 0.1683\n",
      "Epoch 29/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1779 - val_loss: 0.1654\n",
      "Epoch 30/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1765 - val_loss: 0.1658\n",
      "Epoch 31/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.1735 - val_loss: 0.1605\n",
      "Epoch 32/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1714 - val_loss: 0.1599\n",
      "Epoch 33/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.1697 - val_loss: 0.1571\n",
      "Epoch 34/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1676 - val_loss: 0.1555\n",
      "Epoch 35/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.1688 - val_loss: 0.1550\n",
      "Epoch 36/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.1652 - val_loss: 0.1540\n",
      "Epoch 37/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.1650 - val_loss: 0.1511\n",
      "Epoch 38/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1634 - val_loss: 0.1517\n",
      "Epoch 39/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1619 - val_loss: 0.1502\n",
      "Epoch 40/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1601 - val_loss: 0.1499\n",
      "Epoch 41/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1605 - val_loss: 0.1498\n",
      "Epoch 42/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1603 - val_loss: 0.1528\n",
      "Epoch 43/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1586 - val_loss: 0.1476\n",
      "Epoch 44/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1588 - val_loss: 0.1486\n",
      "Epoch 45/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1582 - val_loss: 0.1455\n",
      "Epoch 46/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1581 - val_loss: 0.1469\n",
      "Epoch 47/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1569 - val_loss: 0.1479\n",
      "Epoch 48/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1577 - val_loss: 0.1457\n",
      "Epoch 49/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.1565 - val_loss: 0.1436\n",
      "Epoch 50/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.1562 - val_loss: 0.1465\n",
      "Epoch 51/75\n",
      "141859/141859 [==============================] - 4s 31us/step - loss: 0.1565 - val_loss: 0.1436\n",
      "Epoch 52/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 0.1549 - val_loss: 0.1443\n",
      "Epoch 53/75\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 0.1550 - val_loss: 0.1453\n",
      "Epoch 54/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.1555 - val_loss: 0.1439\n",
      "Epoch 55/75\n",
      "141859/141859 [==============================] - 4s 27us/step - loss: 0.1544 - val_loss: 0.1468\n",
      "Epoch 56/75\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 0.1554 - val_loss: 0.1432\n",
      "Epoch 57/75\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 0.1535 - val_loss: 0.1446\n",
      "Epoch 58/75\n",
      "141859/141859 [==============================] - 4s 26us/step - loss: 0.1537 - val_loss: 0.1441\n",
      "Epoch 59/75\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 0.1546 - val_loss: 0.1447\n",
      "Epoch 60/75\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 0.1515 - val_loss: 0.1415\n",
      "Epoch 61/75\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 0.1524 - val_loss: 0.1403\n",
      "Epoch 62/75\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 0.1535 - val_loss: 0.1432\n",
      "Epoch 63/75\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 0.1531 - val_loss: 0.1426\n",
      "Epoch 64/75\n",
      "141859/141859 [==============================] - 4s 27us/step - loss: 0.1524 - val_loss: 0.1450\n",
      "Epoch 65/75\n",
      "141859/141859 [==============================] - 4s 26us/step - loss: 0.1528 - val_loss: 0.1423\n",
      "Epoch 66/75\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 0.1521 - val_loss: 0.1424\n",
      "Epoch 67/75\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 0.1520 - val_loss: 0.1426\n",
      "Epoch 68/75\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 0.1505 - val_loss: 0.1407\n",
      "Building model 3 of 16\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 2.3610 - val_loss: 0.8648\n",
      "Epoch 2/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.8800 - val_loss: 0.8817\n",
      "Epoch 3/75\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 0.7136 - val_loss: 1.0593\n",
      "Epoch 4/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.6263 - val_loss: 1.0689\n",
      "Epoch 5/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.5613 - val_loss: 1.1556\n",
      "Epoch 6/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.5063 - val_loss: 1.1706\n",
      "Epoch 7/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.4583 - val_loss: 1.2612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.4219 - val_loss: 1.1796\n",
      "Building model 4 of 16\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 2.9935 - val_loss: 1.3761\n",
      "Epoch 2/75\n",
      "141859/141859 [==============================] - 4s 27us/step - loss: 1.2628 - val_loss: 1.5147\n",
      "Epoch 3/75\n",
      "141859/141859 [==============================] - 4s 26us/step - loss: 0.9703 - val_loss: 1.3156\n",
      "Epoch 4/75\n",
      "141859/141859 [==============================] - 4s 26us/step - loss: 0.8253 - val_loss: 1.1696\n",
      "Epoch 5/75\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 0.7034 - val_loss: 0.9196\n",
      "Epoch 6/75\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 0.6201 - val_loss: 0.8219\n",
      "Epoch 7/75\n",
      "141859/141859 [==============================] - 3s 25us/step - loss: 0.5472 - val_loss: 0.6265\n",
      "Epoch 8/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.4974 - val_loss: 0.5542\n",
      "Epoch 9/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.4570 - val_loss: 0.5468\n",
      "Epoch 10/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.4302 - val_loss: 0.4542\n",
      "Epoch 11/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3989 - val_loss: 0.4104\n",
      "Epoch 12/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.3774 - val_loss: 0.3663\n",
      "Epoch 13/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3585 - val_loss: 0.3492\n",
      "Epoch 14/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3407 - val_loss: 0.3373\n",
      "Epoch 15/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3253 - val_loss: 0.3144\n",
      "Epoch 16/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3100 - val_loss: 0.2989\n",
      "Epoch 17/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2981 - val_loss: 0.2819\n",
      "Epoch 18/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2856 - val_loss: 0.2678\n",
      "Epoch 19/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2747 - val_loss: 0.2530\n",
      "Epoch 20/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2623 - val_loss: 0.2464\n",
      "Epoch 21/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2546 - val_loss: 0.2354\n",
      "Epoch 22/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2470 - val_loss: 0.2336\n",
      "Epoch 23/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2387 - val_loss: 0.2255\n",
      "Epoch 24/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2333 - val_loss: 0.2135\n",
      "Epoch 25/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2270 - val_loss: 0.2057\n",
      "Epoch 26/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2207 - val_loss: 0.2084\n",
      "Epoch 27/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2166 - val_loss: 0.2018\n",
      "Epoch 28/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2125 - val_loss: 0.1939\n",
      "Epoch 29/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2088 - val_loss: 0.1916\n",
      "Epoch 30/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2028 - val_loss: 0.1844\n",
      "Epoch 31/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2007 - val_loss: 0.1838\n",
      "Epoch 32/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1982 - val_loss: 0.1804\n",
      "Epoch 33/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1956 - val_loss: 0.1773\n",
      "Epoch 34/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1915 - val_loss: 0.1802\n",
      "Epoch 35/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1905 - val_loss: 0.1766\n",
      "Epoch 36/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1877 - val_loss: 0.1684\n",
      "Epoch 37/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1864 - val_loss: 0.1679\n",
      "Epoch 38/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1853 - val_loss: 0.1746\n",
      "Epoch 39/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1839 - val_loss: 0.1659\n",
      "Epoch 40/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1813 - val_loss: 0.1656\n",
      "Epoch 41/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.1809 - val_loss: 0.1690\n",
      "Epoch 42/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1809 - val_loss: 0.1631\n",
      "Epoch 43/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1796 - val_loss: 0.1667\n",
      "Epoch 44/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1788 - val_loss: 0.1640\n",
      "Epoch 45/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1760 - val_loss: 0.1618\n",
      "Epoch 46/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1774 - val_loss: 0.1625\n",
      "Epoch 47/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1760 - val_loss: 0.1607\n",
      "Epoch 48/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1754 - val_loss: 0.1627\n",
      "Epoch 49/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1750 - val_loss: 0.1584\n",
      "Epoch 50/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.1740 - val_loss: 0.1587\n",
      "Epoch 51/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1733 - val_loss: 0.1560\n",
      "Epoch 52/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1732 - val_loss: 0.1562\n",
      "Epoch 53/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1737 - val_loss: 0.1569\n",
      "Epoch 54/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1720 - val_loss: 0.1560\n",
      "Epoch 55/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1718 - val_loss: 0.1559\n",
      "Epoch 56/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1722 - val_loss: 0.1552\n",
      "Epoch 57/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1723 - val_loss: 0.1563\n",
      "Epoch 58/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1714 - val_loss: 0.1587\n",
      "Epoch 59/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1726 - val_loss: 0.1584\n",
      "Epoch 60/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1708 - val_loss: 0.1521\n",
      "Epoch 61/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1700 - val_loss: 0.1536\n",
      "Epoch 62/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1709 - val_loss: 0.1544\n",
      "Epoch 63/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1699 - val_loss: 0.1558\n",
      "Epoch 64/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1702 - val_loss: 0.1581\n",
      "Epoch 65/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1697 - val_loss: 0.1541\n",
      "Epoch 66/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1693 - val_loss: 0.1549\n",
      "Epoch 67/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1705 - val_loss: 0.1538\n",
      "Building model 5 of 16\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/75\n",
      "141859/141859 [==============================] - 4s 26us/step - loss: 2.1313 - val_loss: 0.6228\n",
      "Epoch 2/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 1.0137 - val_loss: 0.5469\n",
      "Epoch 3/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.9081 - val_loss: 0.5057\n",
      "Epoch 4/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.8400 - val_loss: 0.4747\n",
      "Epoch 5/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.7935 - val_loss: 0.4525\n",
      "Epoch 6/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.7558 - val_loss: 0.4226\n",
      "Epoch 7/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.7191 - val_loss: 0.3888\n",
      "Epoch 8/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.6822 - val_loss: 0.3688\n",
      "Epoch 9/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.6518 - val_loss: 0.3622\n",
      "Epoch 10/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.6229 - val_loss: 0.3370\n",
      "Epoch 11/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.5935 - val_loss: 0.3175\n",
      "Epoch 12/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.5652 - val_loss: 0.3156\n",
      "Epoch 13/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.5405 - val_loss: 0.2901\n",
      "Epoch 14/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.5119 - val_loss: 0.2748\n",
      "Epoch 15/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.4896 - val_loss: 0.2817\n",
      "Epoch 16/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.4688 - val_loss: 0.2463\n",
      "Epoch 17/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.4456 - val_loss: 0.2357\n",
      "Epoch 18/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.4266 - val_loss: 0.2270\n",
      "Epoch 19/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.4062 - val_loss: 0.2212\n",
      "Epoch 20/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.3877 - val_loss: 0.2147\n",
      "Epoch 21/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.3697 - val_loss: 0.2063\n",
      "Epoch 22/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.3557 - val_loss: 0.1989\n",
      "Epoch 23/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.3362 - val_loss: 0.1961\n",
      "Epoch 24/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.3246 - val_loss: 0.1910\n",
      "Epoch 25/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.3081 - val_loss: 0.1820\n",
      "Epoch 26/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2958 - val_loss: 0.1802\n",
      "Epoch 27/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2867 - val_loss: 0.1717\n",
      "Epoch 28/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2787 - val_loss: 0.1679\n",
      "Epoch 29/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2650 - val_loss: 0.1660\n",
      "Epoch 30/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.2560 - val_loss: 0.1648\n",
      "Epoch 31/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2465 - val_loss: 0.1606\n",
      "Epoch 32/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2387 - val_loss: 0.1559\n",
      "Epoch 33/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2294 - val_loss: 0.1580\n",
      "Epoch 34/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2260 - val_loss: 0.1562\n",
      "Epoch 35/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2182 - val_loss: 0.1539\n",
      "Epoch 36/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2129 - val_loss: 0.1533\n",
      "Epoch 37/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2073 - val_loss: 0.1483\n",
      "Epoch 38/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2040 - val_loss: 0.1493\n",
      "Epoch 39/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1985 - val_loss: 0.1477\n",
      "Epoch 40/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1937 - val_loss: 0.1423\n",
      "Epoch 41/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1909 - val_loss: 0.1481\n",
      "Epoch 42/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1883 - val_loss: 0.1421\n",
      "Epoch 43/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1858 - val_loss: 0.1400\n",
      "Epoch 44/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1820 - val_loss: 0.1434\n",
      "Epoch 45/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1814 - val_loss: 0.1417\n",
      "Epoch 46/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1768 - val_loss: 0.1373\n",
      "Epoch 47/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1761 - val_loss: 0.1399\n",
      "Epoch 48/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1753 - val_loss: 0.1383\n",
      "Epoch 49/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1739 - val_loss: 0.1370\n",
      "Epoch 50/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1730 - val_loss: 0.1381\n",
      "Epoch 51/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1709 - val_loss: 0.1365\n",
      "Epoch 52/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1700 - val_loss: 0.1392\n",
      "Epoch 53/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1681 - val_loss: 0.1365\n",
      "Epoch 54/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.1677 - val_loss: 0.1339\n",
      "Epoch 55/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1682 - val_loss: 0.1347\n",
      "Epoch 56/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1671 - val_loss: 0.1322\n",
      "Epoch 57/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1648 - val_loss: 0.1317\n",
      "Epoch 58/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1659 - val_loss: 0.1366\n",
      "Epoch 59/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1662 - val_loss: 0.1349\n",
      "Epoch 60/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1658 - val_loss: 0.1328\n",
      "Epoch 61/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1657 - val_loss: 0.1376\n",
      "Epoch 62/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1658 - val_loss: 0.1362\n",
      "Epoch 63/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1653 - val_loss: 0.1340\n",
      "Epoch 64/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1643 - val_loss: 0.1329\n",
      "Building model 6 of 16\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 3.3722 - val_loss: 0.9873\n",
      "Epoch 2/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 1.5262 - val_loss: 0.9355\n",
      "Epoch 3/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 1.2969 - val_loss: 0.8505\n",
      "Epoch 4/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 1.1537 - val_loss: 0.8987\n",
      "Epoch 5/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 1.0364 - val_loss: 0.8131\n",
      "Epoch 6/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.9497 - val_loss: 0.7597\n",
      "Epoch 7/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.8852 - val_loss: 0.6122\n",
      "Epoch 8/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.8301 - val_loss: 0.5703\n",
      "Epoch 9/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.7968 - val_loss: 0.5000\n",
      "Epoch 10/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.7579 - val_loss: 0.4622\n",
      "Epoch 11/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.7217 - val_loss: 0.4175\n",
      "Epoch 12/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.6890 - val_loss: 0.4032\n",
      "Epoch 13/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.6632 - val_loss: 0.3849\n",
      "Epoch 14/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.6332 - val_loss: 0.3694\n",
      "Epoch 15/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.6065 - val_loss: 0.3461\n",
      "Epoch 16/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.5765 - val_loss: 0.3278\n",
      "Epoch 17/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.5512 - val_loss: 0.3122\n",
      "Epoch 18/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.5273 - val_loss: 0.2925\n",
      "Epoch 19/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.5034 - val_loss: 0.2876\n",
      "Epoch 20/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.4805 - val_loss: 0.2682\n",
      "Epoch 21/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.4604 - val_loss: 0.2567\n",
      "Epoch 22/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.4403 - val_loss: 0.2468\n",
      "Epoch 23/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.4194 - val_loss: 0.2345\n",
      "Epoch 24/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.4015 - val_loss: 0.2363\n",
      "Epoch 25/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.3832 - val_loss: 0.2235\n",
      "Epoch 26/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3681 - val_loss: 0.2185\n",
      "Epoch 27/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3533 - val_loss: 0.2063\n",
      "Epoch 28/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3377 - val_loss: 0.2047\n",
      "Epoch 29/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.3287 - val_loss: 0.2027\n",
      "Epoch 30/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3113 - val_loss: 0.1905\n",
      "Epoch 31/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3015 - val_loss: 0.1897\n",
      "Epoch 32/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2897 - val_loss: 0.1847\n",
      "Epoch 33/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2816 - val_loss: 0.1828\n",
      "Epoch 34/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2695 - val_loss: 0.1778\n",
      "Epoch 35/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2609 - val_loss: 0.1789\n",
      "Epoch 36/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2533 - val_loss: 0.1741\n",
      "Epoch 37/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2456 - val_loss: 0.1671\n",
      "Epoch 38/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2391 - val_loss: 0.1667\n",
      "Epoch 39/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2346 - val_loss: 0.1686\n",
      "Epoch 40/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2293 - val_loss: 0.1654\n",
      "Epoch 41/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2228 - val_loss: 0.1635\n",
      "Epoch 42/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2195 - val_loss: 0.1605\n",
      "Epoch 43/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2169 - val_loss: 0.1634\n",
      "Epoch 44/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2127 - val_loss: 0.1590\n",
      "Epoch 45/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2111 - val_loss: 0.1602\n",
      "Epoch 46/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2066 - val_loss: 0.1592\n",
      "Epoch 47/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2038 - val_loss: 0.1556\n",
      "Epoch 48/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2008 - val_loss: 0.1538\n",
      "Epoch 49/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2002 - val_loss: 0.1530\n",
      "Epoch 50/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.1985 - val_loss: 0.1552\n",
      "Epoch 51/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1963 - val_loss: 0.1552\n",
      "Epoch 52/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.1965 - val_loss: 0.1543\n",
      "Epoch 53/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1949 - val_loss: 0.1603\n",
      "Epoch 54/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1941 - val_loss: 0.1560\n",
      "Epoch 55/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.1938 - val_loss: 0.1547\n",
      "Epoch 56/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1934 - val_loss: 0.1512\n",
      "Epoch 57/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1908 - val_loss: 0.1498\n",
      "Epoch 58/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1908 - val_loss: 0.1499\n",
      "Epoch 59/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1902 - val_loss: 0.1507\n",
      "Epoch 60/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1892 - val_loss: 0.1488\n",
      "Epoch 61/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1911 - val_loss: 0.1493\n",
      "Epoch 62/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1896 - val_loss: 0.1508\n",
      "Epoch 63/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1887 - val_loss: 0.1478\n",
      "Epoch 64/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1889 - val_loss: 0.1496\n",
      "Epoch 65/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1883 - val_loss: 0.1462\n",
      "Epoch 66/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1877 - val_loss: 0.1478\n",
      "Epoch 67/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1879 - val_loss: 0.1471\n",
      "Epoch 68/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1873 - val_loss: 0.1449\n",
      "Epoch 69/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1869 - val_loss: 0.1463\n",
      "Epoch 70/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1879 - val_loss: 0.1452\n",
      "Epoch 71/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1850 - val_loss: 0.1455\n",
      "Epoch 72/75\n",
      "141859/141859 [==============================] - 3s 25us/step - loss: 0.1853 - val_loss: 0.1452\n",
      "Epoch 73/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1859 - val_loss: 0.1504\n",
      "Epoch 74/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1840 - val_loss: 0.1452\n",
      "Epoch 75/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1845 - val_loss: 0.1451\n",
      "Building model 7 of 16\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 3.3149 - val_loss: 0.8533\n",
      "Epoch 2/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 1.5448 - val_loss: 0.6451\n",
      "Epoch 3/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 1.2690 - val_loss: 0.5951\n",
      "Epoch 4/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 1.1282 - val_loss: 0.5356\n",
      "Epoch 5/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 1.0212 - val_loss: 0.4780\n",
      "Epoch 6/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.9349 - val_loss: 0.4559\n",
      "Epoch 7/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.8645 - val_loss: 0.4578\n",
      "Epoch 8/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.8112 - val_loss: 0.4148\n",
      "Epoch 9/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.7662 - val_loss: 0.3992\n",
      "Epoch 10/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.7284 - val_loss: 0.3830\n",
      "Epoch 11/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.6987 - val_loss: 0.3690\n",
      "Epoch 12/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.6685 - val_loss: 0.3598\n",
      "Epoch 13/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.6394 - val_loss: 0.3454\n",
      "Epoch 14/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.6129 - val_loss: 0.3297\n",
      "Epoch 15/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.5868 - val_loss: 0.3156\n",
      "Epoch 16/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.5639 - val_loss: 0.3095\n",
      "Epoch 17/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.5379 - val_loss: 0.2948\n",
      "Epoch 18/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.5175 - val_loss: 0.2817\n",
      "Epoch 19/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.4965 - val_loss: 0.2697\n",
      "Epoch 20/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.4772 - val_loss: 0.2644\n",
      "Epoch 21/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.4528 - val_loss: 0.2480\n",
      "Epoch 22/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.4354 - val_loss: 0.2383\n",
      "Epoch 23/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.4159 - val_loss: 0.2335\n",
      "Epoch 24/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.4004 - val_loss: 0.2274\n",
      "Epoch 25/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3839 - val_loss: 0.2191\n",
      "Epoch 26/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3690 - val_loss: 0.2088\n",
      "Epoch 27/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3516 - val_loss: 0.2033\n",
      "Epoch 28/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3361 - val_loss: 0.1983\n",
      "Epoch 29/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3248 - val_loss: 0.1966\n",
      "Epoch 30/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3114 - val_loss: 0.1878\n",
      "Epoch 31/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2987 - val_loss: 0.1827\n",
      "Epoch 32/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2879 - val_loss: 0.1791\n",
      "Epoch 33/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2760 - val_loss: 0.1793\n",
      "Epoch 34/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2674 - val_loss: 0.1772\n",
      "Epoch 35/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2585 - val_loss: 0.1737\n",
      "Epoch 36/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2499 - val_loss: 0.1695\n",
      "Epoch 37/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2438 - val_loss: 0.1632\n",
      "Epoch 38/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2352 - val_loss: 0.1581\n",
      "Epoch 39/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2291 - val_loss: 0.1588\n",
      "Epoch 40/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2231 - val_loss: 0.1576\n",
      "Epoch 41/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2188 - val_loss: 0.1549\n",
      "Epoch 42/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2132 - val_loss: 0.1513\n",
      "Epoch 43/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2076 - val_loss: 0.1544\n",
      "Epoch 44/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2050 - val_loss: 0.1504\n",
      "Epoch 45/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2008 - val_loss: 0.1525\n",
      "Epoch 46/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1995 - val_loss: 0.1468\n",
      "Epoch 47/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1952 - val_loss: 0.1457\n",
      "Epoch 48/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1922 - val_loss: 0.1458\n",
      "Epoch 49/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1914 - val_loss: 0.1446\n",
      "Epoch 50/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1899 - val_loss: 0.1465\n",
      "Epoch 51/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1896 - val_loss: 0.1460\n",
      "Epoch 52/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1874 - val_loss: 0.1449\n",
      "Epoch 53/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1840 - val_loss: 0.1459\n",
      "Epoch 54/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1856 - val_loss: 0.1450\n",
      "Epoch 55/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1842 - val_loss: 0.1442\n",
      "Epoch 56/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1825 - val_loss: 0.1409\n",
      "Epoch 57/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1800 - val_loss: 0.1390\n",
      "Epoch 58/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1804 - val_loss: 0.1439\n",
      "Epoch 59/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1799 - val_loss: 0.1416\n",
      "Epoch 60/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1798 - val_loss: 0.1412\n",
      "Epoch 61/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1799 - val_loss: 0.1347\n",
      "Epoch 62/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1794 - val_loss: 0.1424\n",
      "Epoch 63/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1781 - val_loss: 0.1380\n",
      "Epoch 64/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1775 - val_loss: 0.1363\n",
      "Epoch 65/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1762 - val_loss: 0.1358\n",
      "Epoch 66/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.1765 - val_loss: 0.1455\n",
      "Epoch 67/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.1826 - val_loss: 0.1399\n",
      "Epoch 68/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.1770 - val_loss: 0.1409\n",
      "Building model 8 of 16\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/75\n",
      "141859/141859 [==============================] - 5s 32us/step - loss: 4.4487 - val_loss: 1.9943\n",
      "Epoch 2/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 2.0650 - val_loss: 1.5986\n",
      "Epoch 3/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 1.6624 - val_loss: 1.3081\n",
      "Epoch 4/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 1.4505 - val_loss: 1.1003\n",
      "Epoch 5/75\n",
      "141859/141859 [==============================] - 3s 25us/step - loss: 1.2713 - val_loss: 0.8649\n",
      "Epoch 6/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 1.1398 - val_loss: 0.7441\n",
      "Epoch 7/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 1.0380 - val_loss: 0.6159\n",
      "Epoch 8/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.9544 - val_loss: 0.5865\n",
      "Epoch 9/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.8941 - val_loss: 0.5035\n",
      "Epoch 10/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.8298 - val_loss: 0.4493\n",
      "Epoch 11/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.7875 - val_loss: 0.4325\n",
      "Epoch 12/75\n",
      "141859/141859 [==============================] - 3s 25us/step - loss: 0.7473 - val_loss: 0.4072\n",
      "Epoch 13/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.7079 - val_loss: 0.3815\n",
      "Epoch 14/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.6786 - val_loss: 0.3610\n",
      "Epoch 15/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.6482 - val_loss: 0.3400\n",
      "Epoch 16/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.6228 - val_loss: 0.3217\n",
      "Epoch 17/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.5948 - val_loss: 0.3057\n",
      "Epoch 18/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.5712 - val_loss: 0.2946\n",
      "Epoch 19/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.5504 - val_loss: 0.2752\n",
      "Epoch 20/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.5235 - val_loss: 0.2712\n",
      "Epoch 21/75\n",
      "141859/141859 [==============================] - 4s 27us/step - loss: 0.5020 - val_loss: 0.2632\n",
      "Epoch 22/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.4789 - val_loss: 0.2471\n",
      "Epoch 23/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.4566 - val_loss: 0.2349\n",
      "Epoch 24/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.4392 - val_loss: 0.2372\n",
      "Epoch 25/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.4241 - val_loss: 0.2283\n",
      "Epoch 26/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.4103 - val_loss: 0.2184\n",
      "Epoch 27/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.3937 - val_loss: 0.2146\n",
      "Epoch 28/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.3782 - val_loss: 0.2098\n",
      "Epoch 29/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.3649 - val_loss: 0.2071\n",
      "Epoch 30/75\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 0.3511 - val_loss: 0.2007\n",
      "Epoch 31/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.3375 - val_loss: 0.1933\n",
      "Epoch 32/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.3290 - val_loss: 0.1909\n",
      "Epoch 33/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.3186 - val_loss: 0.1883\n",
      "Epoch 34/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.3075 - val_loss: 0.1792\n",
      "Epoch 35/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2973 - val_loss: 0.1820\n",
      "Epoch 36/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2910 - val_loss: 0.1795\n",
      "Epoch 37/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2825 - val_loss: 0.1778\n",
      "Epoch 38/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2749 - val_loss: 0.1769\n",
      "Epoch 39/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2715 - val_loss: 0.1812\n",
      "Epoch 40/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2628 - val_loss: 0.1743\n",
      "Epoch 41/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2572 - val_loss: 0.1728\n",
      "Epoch 42/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2518 - val_loss: 0.1675\n",
      "Epoch 43/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2471 - val_loss: 0.1742\n",
      "Epoch 44/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2436 - val_loss: 0.1642\n",
      "Epoch 45/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2393 - val_loss: 0.1654\n",
      "Epoch 46/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2381 - val_loss: 0.1667\n",
      "Epoch 47/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2322 - val_loss: 0.1707\n",
      "Epoch 48/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2304 - val_loss: 0.1633\n",
      "Epoch 49/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2261 - val_loss: 0.1699\n",
      "Epoch 50/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2254 - val_loss: 0.1698\n",
      "Epoch 51/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2239 - val_loss: 0.1618\n",
      "Epoch 52/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2205 - val_loss: 0.1649\n",
      "Epoch 53/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2187 - val_loss: 0.1632\n",
      "Epoch 54/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2176 - val_loss: 0.1598\n",
      "Epoch 55/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2164 - val_loss: 0.1593\n",
      "Epoch 56/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2145 - val_loss: 0.1646\n",
      "Epoch 57/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2128 - val_loss: 0.1603\n",
      "Epoch 58/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2137 - val_loss: 0.1605\n",
      "Epoch 59/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2125 - val_loss: 0.1608\n",
      "Epoch 60/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2097 - val_loss: 0.1586\n",
      "Epoch 61/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2106 - val_loss: 0.1619\n",
      "Epoch 62/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2105 - val_loss: 0.1562\n",
      "Epoch 63/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2113 - val_loss: 0.1574\n",
      "Epoch 64/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2112 - val_loss: 0.1575\n",
      "Epoch 65/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2100 - val_loss: 0.1593\n",
      "Epoch 66/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2082 - val_loss: 0.1601\n",
      "Epoch 67/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2072 - val_loss: 0.1570\n",
      "Epoch 68/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2076 - val_loss: 0.1597\n",
      "Epoch 69/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2096 - val_loss: 0.1606\n",
      "Building model 9 of 16\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/75\n",
      "141859/141859 [==============================] - 4s 26us/step - loss: 4.8343 - val_loss: 2.8457\n",
      "Epoch 2/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 2.2954 - val_loss: 1.8623\n",
      "Epoch 3/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 1.5631 - val_loss: 1.3097\n",
      "Epoch 4/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 1.1257 - val_loss: 0.9679\n",
      "Epoch 5/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.8477 - val_loss: 0.7454\n",
      "Epoch 6/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.6664 - val_loss: 0.5945\n",
      "Epoch 7/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.5404 - val_loss: 0.4934\n",
      "Epoch 8/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.4512 - val_loss: 0.4143\n",
      "Epoch 9/75\n",
      "141859/141859 [==============================] - 2s 18us/step - loss: 0.3954 - val_loss: 0.3605\n",
      "Epoch 10/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.3406 - val_loss: 0.3238\n",
      "Epoch 11/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.3052 - val_loss: 0.2949\n",
      "Epoch 12/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.2802 - val_loss: 0.2739\n",
      "Epoch 13/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.2588 - val_loss: 0.2501\n",
      "Epoch 14/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.2442 - val_loss: 0.2376\n",
      "Epoch 15/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.2309 - val_loss: 0.2291\n",
      "Epoch 16/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.2228 - val_loss: 0.2221\n",
      "Epoch 17/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.2158 - val_loss: 0.2142\n",
      "Epoch 18/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.2104 - val_loss: 0.2079\n",
      "Epoch 19/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.2070 - val_loss: 0.2047\n",
      "Epoch 20/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.2034 - val_loss: 0.2024\n",
      "Epoch 21/75\n",
      "141859/141859 [==============================] - 2s 18us/step - loss: 0.2008 - val_loss: 0.2022\n",
      "Epoch 22/75\n",
      "141859/141859 [==============================] - 2s 17us/step - loss: 0.1987 - val_loss: 0.1999\n",
      "Epoch 23/75\n",
      "141859/141859 [==============================] - 2s 18us/step - loss: 0.1950 - val_loss: 0.1937\n",
      "Epoch 24/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1950 - val_loss: 0.1936\n",
      "Epoch 25/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1932 - val_loss: 0.1922\n",
      "Epoch 26/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1904 - val_loss: 0.1911\n",
      "Epoch 27/75\n",
      "141859/141859 [==============================] - 2s 18us/step - loss: 0.1890 - val_loss: 0.1875\n",
      "Epoch 28/75\n",
      "141859/141859 [==============================] - 2s 18us/step - loss: 0.1878 - val_loss: 0.1921\n",
      "Epoch 29/75\n",
      "141859/141859 [==============================] - 2s 18us/step - loss: 0.1877 - val_loss: 0.1888\n",
      "Epoch 30/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1883 - val_loss: 0.1872\n",
      "Epoch 31/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1856 - val_loss: 0.1862\n",
      "Epoch 32/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1853 - val_loss: 0.1847\n",
      "Epoch 33/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1831 - val_loss: 0.1850\n",
      "Epoch 34/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1834 - val_loss: 0.1853\n",
      "Epoch 35/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1825 - val_loss: 0.1821\n",
      "Epoch 36/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1823 - val_loss: 0.1843\n",
      "Epoch 37/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1820 - val_loss: 0.1881\n",
      "Epoch 38/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1800 - val_loss: 0.1808\n",
      "Epoch 39/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1794 - val_loss: 0.1870\n",
      "Epoch 40/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1798 - val_loss: 0.1794\n",
      "Epoch 41/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1771 - val_loss: 0.1811\n",
      "Epoch 42/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1776 - val_loss: 0.1793\n",
      "Epoch 43/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1777 - val_loss: 0.1781\n",
      "Epoch 44/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1769 - val_loss: 0.1766\n",
      "Epoch 45/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1767 - val_loss: 0.1776\n",
      "Epoch 46/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1749 - val_loss: 0.1820\n",
      "Epoch 47/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1756 - val_loss: 0.1771\n",
      "Epoch 48/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1743 - val_loss: 0.1825\n",
      "Epoch 49/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1754 - val_loss: 0.1773\n",
      "Epoch 50/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1738 - val_loss: 0.1740\n",
      "Epoch 51/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1739 - val_loss: 0.1757\n",
      "Epoch 52/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1728 - val_loss: 0.1728\n",
      "Epoch 53/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1729 - val_loss: 0.1732\n",
      "Epoch 54/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1723 - val_loss: 0.1821\n",
      "Epoch 55/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1733 - val_loss: 0.1720\n",
      "Epoch 56/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1715 - val_loss: 0.1719\n",
      "Epoch 57/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1713 - val_loss: 0.1709\n",
      "Epoch 58/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1713 - val_loss: 0.1730\n",
      "Epoch 59/75\n",
      "141859/141859 [==============================] - 2s 18us/step - loss: 0.1702 - val_loss: 0.1740\n",
      "Epoch 60/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1703 - val_loss: 0.1718\n",
      "Epoch 61/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1701 - val_loss: 0.1748\n",
      "Epoch 62/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1701 - val_loss: 0.1726\n",
      "Epoch 63/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1693 - val_loss: 0.1744\n",
      "Epoch 64/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1687 - val_loss: 0.1685\n",
      "Epoch 65/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1684 - val_loss: 0.1710\n",
      "Epoch 66/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1687 - val_loss: 0.1722\n",
      "Epoch 67/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1681 - val_loss: 0.1689\n",
      "Epoch 68/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1683 - val_loss: 0.1690\n",
      "Epoch 69/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1679 - val_loss: 0.1714\n",
      "Epoch 70/75\n",
      "141859/141859 [==============================] - 2s 18us/step - loss: 0.1675 - val_loss: 0.1672\n",
      "Epoch 71/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1657 - val_loss: 0.1669\n",
      "Epoch 72/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1667 - val_loss: 0.1678\n",
      "Epoch 73/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1666 - val_loss: 0.1680\n",
      "Epoch 74/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1671 - val_loss: 0.1753\n",
      "Epoch 75/75\n",
      "141859/141859 [==============================] - 3s 18us/step - loss: 0.1683 - val_loss: 0.1677\n",
      "Building model 10 of 16\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/75\n",
      "141859/141859 [==============================] - 4s 30us/step - loss: 5.5974 - val_loss: 3.1142\n",
      "Epoch 2/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 2.7367 - val_loss: 2.1107\n",
      "Epoch 3/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 1.8445 - val_loss: 1.4980\n",
      "Epoch 4/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 1.3252 - val_loss: 1.1192\n",
      "Epoch 5/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 1.0116 - val_loss: 0.8701\n",
      "Epoch 6/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.8046 - val_loss: 0.7083\n",
      "Epoch 7/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.6617 - val_loss: 0.5893\n",
      "Epoch 8/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.5602 - val_loss: 0.5068\n",
      "Epoch 9/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.4883 - val_loss: 0.4443\n",
      "Epoch 10/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.4317 - val_loss: 0.3969\n",
      "Epoch 11/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.3896 - val_loss: 0.3597\n",
      "Epoch 12/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.3571 - val_loss: 0.3310\n",
      "Epoch 13/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.3352 - val_loss: 0.3126\n",
      "Epoch 14/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.3145 - val_loss: 0.2947\n",
      "Epoch 15/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2994 - val_loss: 0.2802\n",
      "Epoch 16/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2858 - val_loss: 0.2661\n",
      "Epoch 17/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2741 - val_loss: 0.2581\n",
      "Epoch 18/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2657 - val_loss: 0.2485\n",
      "Epoch 19/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2581 - val_loss: 0.2438\n",
      "Epoch 20/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2544 - val_loss: 0.2413\n",
      "Epoch 21/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2510 - val_loss: 0.2382\n",
      "Epoch 22/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2461 - val_loss: 0.2310\n",
      "Epoch 23/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2430 - val_loss: 0.2303\n",
      "Epoch 24/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2395 - val_loss: 0.2265\n",
      "Epoch 25/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2364 - val_loss: 0.2228\n",
      "Epoch 26/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2346 - val_loss: 0.2211\n",
      "Epoch 27/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2385 - val_loss: 0.2191\n",
      "Epoch 28/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2328 - val_loss: 0.2175\n",
      "Epoch 29/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2316 - val_loss: 0.2216\n",
      "Epoch 30/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2313 - val_loss: 0.2185\n",
      "Epoch 31/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2306 - val_loss: 0.2157\n",
      "Epoch 32/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2275 - val_loss: 0.2169\n",
      "Epoch 33/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2268 - val_loss: 0.2173\n",
      "Epoch 34/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2271 - val_loss: 0.2142\n",
      "Epoch 35/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2273 - val_loss: 0.2167\n",
      "Epoch 36/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2256 - val_loss: 0.2124\n",
      "Epoch 37/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2254 - val_loss: 0.2113\n",
      "Epoch 38/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2262 - val_loss: 0.2144\n",
      "Epoch 39/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2254 - val_loss: 0.2109\n",
      "Epoch 40/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2235 - val_loss: 0.2084\n",
      "Epoch 41/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2227 - val_loss: 0.2087\n",
      "Epoch 42/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2218 - val_loss: 0.2118\n",
      "Epoch 43/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2219 - val_loss: 0.2094\n",
      "Epoch 44/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2209 - val_loss: 0.2067\n",
      "Epoch 45/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2258 - val_loss: 0.2131\n",
      "Epoch 46/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2226 - val_loss: 0.2070\n",
      "Epoch 47/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2200 - val_loss: 0.2056\n",
      "Epoch 48/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2202 - val_loss: 0.2072\n",
      "Epoch 49/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2194 - val_loss: 0.2063\n",
      "Epoch 50/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2180 - val_loss: 0.2061\n",
      "Epoch 51/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2184 - val_loss: 0.2063\n",
      "Epoch 52/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2169 - val_loss: 0.2032\n",
      "Epoch 53/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2159 - val_loss: 0.2025\n",
      "Epoch 54/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2198 - val_loss: 0.2118\n",
      "Epoch 55/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2192 - val_loss: 0.2059\n",
      "Epoch 56/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2160 - val_loss: 0.2034\n",
      "Epoch 57/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2153 - val_loss: 0.2023\n",
      "Epoch 58/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2147 - val_loss: 0.2052\n",
      "Epoch 59/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2156 - val_loss: 0.2026\n",
      "Epoch 60/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2151 - val_loss: 0.2028\n",
      "Epoch 61/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2174 - val_loss: 0.2013\n",
      "Epoch 62/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2153 - val_loss: 0.2040\n",
      "Epoch 63/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2148 - val_loss: 0.2028\n",
      "Epoch 64/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2142 - val_loss: 0.2013\n",
      "Epoch 65/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2143 - val_loss: 0.2049\n",
      "Epoch 66/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2130 - val_loss: 0.2019\n",
      "Epoch 67/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2134 - val_loss: 0.2000\n",
      "Epoch 68/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2114 - val_loss: 0.1987\n",
      "Epoch 69/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2143 - val_loss: 0.2006\n",
      "Epoch 70/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2117 - val_loss: 0.2005\n",
      "Epoch 71/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2114 - val_loss: 0.1975\n",
      "Epoch 72/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2147 - val_loss: 0.2032\n",
      "Epoch 73/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2131 - val_loss: 0.1980\n",
      "Epoch 74/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2114 - val_loss: 0.1990\n",
      "Epoch 75/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.2124 - val_loss: 0.1972\n",
      "Building model 11 of 16\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 5.8954 - val_loss: 3.2436\n",
      "Epoch 2/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 2.8923 - val_loss: 2.2058\n",
      "Epoch 3/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 2.0713 - val_loss: 1.6435\n",
      "Epoch 4/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 1.5814 - val_loss: 1.2785\n",
      "Epoch 5/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 1.2471 - val_loss: 1.0223\n",
      "Epoch 6/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 1.0069 - val_loss: 0.8385\n",
      "Epoch 7/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.8295 - val_loss: 0.6977\n",
      "Epoch 8/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.6950 - val_loss: 0.5946\n",
      "Epoch 9/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.5964 - val_loss: 0.5126\n",
      "Epoch 10/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.5146 - val_loss: 0.4504\n",
      "Epoch 11/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.4541 - val_loss: 0.4000\n",
      "Epoch 12/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.4060 - val_loss: 0.3606\n",
      "Epoch 13/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.3690 - val_loss: 0.3305\n",
      "Epoch 14/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.3373 - val_loss: 0.3052\n",
      "Epoch 15/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.3179 - val_loss: 0.2828\n",
      "Epoch 16/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2946 - val_loss: 0.2695\n",
      "Epoch 17/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2799 - val_loss: 0.2571\n",
      "Epoch 18/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2668 - val_loss: 0.2461\n",
      "Epoch 19/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2577 - val_loss: 0.2373\n",
      "Epoch 20/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2494 - val_loss: 0.2300\n",
      "Epoch 21/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2437 - val_loss: 0.2254\n",
      "Epoch 22/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2384 - val_loss: 0.2190\n",
      "Epoch 23/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2344 - val_loss: 0.2190\n",
      "Epoch 24/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2298 - val_loss: 0.2132\n",
      "Epoch 25/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2264 - val_loss: 0.2092\n",
      "Epoch 26/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2234 - val_loss: 0.2069\n",
      "Epoch 27/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2227 - val_loss: 0.2059\n",
      "Epoch 28/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2188 - val_loss: 0.2060\n",
      "Epoch 29/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2170 - val_loss: 0.2015\n",
      "Epoch 30/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2157 - val_loss: 0.2012\n",
      "Epoch 31/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2150 - val_loss: 0.1993\n",
      "Epoch 32/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2131 - val_loss: 0.1952\n",
      "Epoch 33/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2115 - val_loss: 0.1987\n",
      "Epoch 34/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2100 - val_loss: 0.1946\n",
      "Epoch 35/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2091 - val_loss: 0.1954\n",
      "Epoch 36/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2104 - val_loss: 0.1954\n",
      "Epoch 37/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2072 - val_loss: 0.1925\n",
      "Epoch 38/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2054 - val_loss: 0.1926\n",
      "Epoch 39/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2037 - val_loss: 0.1925\n",
      "Epoch 40/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2061 - val_loss: 0.1886\n",
      "Epoch 41/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2035 - val_loss: 0.1900\n",
      "Epoch 42/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2040 - val_loss: 0.1879\n",
      "Epoch 43/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2026 - val_loss: 0.1862\n",
      "Epoch 44/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2022 - val_loss: 0.1884\n",
      "Epoch 45/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2012 - val_loss: 0.1880\n",
      "Epoch 46/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2006 - val_loss: 0.1883\n",
      "Epoch 47/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2005 - val_loss: 0.1875\n",
      "Epoch 48/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2012 - val_loss: 0.1862\n",
      "Epoch 49/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1990 - val_loss: 0.1840\n",
      "Epoch 50/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2005 - val_loss: 0.1828\n",
      "Epoch 51/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1979 - val_loss: 0.1850\n",
      "Epoch 52/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1985 - val_loss: 0.1815\n",
      "Epoch 53/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1973 - val_loss: 0.1831\n",
      "Epoch 54/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1967 - val_loss: 0.1794\n",
      "Epoch 55/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1952 - val_loss: 0.1814\n",
      "Epoch 56/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1963 - val_loss: 0.1814\n",
      "Epoch 57/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.1958 - val_loss: 0.1834\n",
      "Epoch 58/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1942 - val_loss: 0.1798\n",
      "Epoch 59/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1944 - val_loss: 0.1817\n",
      "Epoch 60/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1938 - val_loss: 0.1776\n",
      "Epoch 61/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1929 - val_loss: 0.1818\n",
      "Epoch 62/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1938 - val_loss: 0.1775\n",
      "Epoch 63/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1937 - val_loss: 0.1765\n",
      "Epoch 64/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1921 - val_loss: 0.1778\n",
      "Epoch 65/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1925 - val_loss: 0.1783\n",
      "Epoch 66/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1919 - val_loss: 0.1767\n",
      "Epoch 67/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1915 - val_loss: 0.1788\n",
      "Epoch 68/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1901 - val_loss: 0.1750\n",
      "Epoch 69/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1903 - val_loss: 0.1773\n",
      "Epoch 70/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1900 - val_loss: 0.1757\n",
      "Epoch 71/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.1892 - val_loss: 0.1748\n",
      "Epoch 72/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1887 - val_loss: 0.1755\n",
      "Epoch 73/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1881 - val_loss: 0.1762\n",
      "Epoch 74/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1880 - val_loss: 0.1740\n",
      "Epoch 75/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.1886 - val_loss: 0.1751\n",
      "Building model 12 of 16\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/75\n",
      "141859/141859 [==============================] - 5s 33us/step - loss: 6.1976 - val_loss: 3.5610\n",
      "Epoch 2/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 3.3353 - val_loss: 2.5294\n",
      "Epoch 3/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 2.3648 - val_loss: 1.8406\n",
      "Epoch 4/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 1.7532 - val_loss: 1.4070\n",
      "Epoch 5/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 1.3548 - val_loss: 1.1184\n",
      "Epoch 6/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 1.0775 - val_loss: 0.9044\n",
      "Epoch 7/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.8815 - val_loss: 0.7521\n",
      "Epoch 8/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.7372 - val_loss: 0.6327\n",
      "Epoch 9/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.6290 - val_loss: 0.5437\n",
      "Epoch 10/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.5461 - val_loss: 0.4768\n",
      "Epoch 11/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.4807 - val_loss: 0.4230\n",
      "Epoch 12/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.4327 - val_loss: 0.3806\n",
      "Epoch 13/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.3922 - val_loss: 0.3478\n",
      "Epoch 14/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.3625 - val_loss: 0.3220\n",
      "Epoch 15/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.3384 - val_loss: 0.3019\n",
      "Epoch 16/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.3187 - val_loss: 0.2847\n",
      "Epoch 17/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.3049 - val_loss: 0.2741\n",
      "Epoch 18/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2921 - val_loss: 0.2646\n",
      "Epoch 19/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2833 - val_loss: 0.2562\n",
      "Epoch 20/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2779 - val_loss: 0.2519\n",
      "Epoch 21/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2695 - val_loss: 0.2459\n",
      "Epoch 22/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2636 - val_loss: 0.2391\n",
      "Epoch 23/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2600 - val_loss: 0.2345\n",
      "Epoch 24/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2571 - val_loss: 0.2343\n",
      "Epoch 25/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2558 - val_loss: 0.2308\n",
      "Epoch 26/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2531 - val_loss: 0.2283\n",
      "Epoch 27/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2508 - val_loss: 0.2313\n",
      "Epoch 28/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2501 - val_loss: 0.2278\n",
      "Epoch 29/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2487 - val_loss: 0.2277\n",
      "Epoch 30/75\n",
      "141859/141859 [==============================] - 3s 25us/step - loss: 0.2484 - val_loss: 0.2257\n",
      "Epoch 31/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2487 - val_loss: 0.2306\n",
      "Epoch 32/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2471 - val_loss: 0.2275\n",
      "Epoch 33/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2459 - val_loss: 0.2273\n",
      "Epoch 34/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2473 - val_loss: 0.2238\n",
      "Epoch 35/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2454 - val_loss: 0.2267\n",
      "Epoch 36/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2453 - val_loss: 0.2253\n",
      "Epoch 37/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2448 - val_loss: 0.2226\n",
      "Epoch 38/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2459 - val_loss: 0.2256\n",
      "Epoch 39/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2448 - val_loss: 0.2263\n",
      "Epoch 40/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2480 - val_loss: 0.2314\n",
      "Epoch 41/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2471 - val_loss: 0.2236\n",
      "Epoch 42/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2441 - val_loss: 0.2224\n",
      "Epoch 43/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2439 - val_loss: 0.2203\n",
      "Epoch 44/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2442 - val_loss: 0.2239\n",
      "Epoch 45/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2428 - val_loss: 0.2219\n",
      "Epoch 46/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2437 - val_loss: 0.2265\n",
      "Epoch 47/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2441 - val_loss: 0.2247\n",
      "Epoch 48/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2434 - val_loss: 0.2215\n",
      "Epoch 49/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2397 - val_loss: 0.2216\n",
      "Epoch 50/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2407 - val_loss: 0.2217\n",
      "Building model 13 of 16\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/75\n",
      "141859/141859 [==============================] - 4s 29us/step - loss: 6.0624 - val_loss: 3.1728\n",
      "Epoch 2/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 3.2502 - val_loss: 2.1927\n",
      "Epoch 3/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 2.4135 - val_loss: 1.6180\n",
      "Epoch 4/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 1.8957 - val_loss: 1.1806\n",
      "Epoch 5/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 1.5464 - val_loss: 0.9042\n",
      "Epoch 6/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 1.2982 - val_loss: 0.7325\n",
      "Epoch 7/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 1.1206 - val_loss: 0.5848\n",
      "Epoch 8/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.9865 - val_loss: 0.4944\n",
      "Epoch 9/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.8830 - val_loss: 0.4160\n",
      "Epoch 10/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.8175 - val_loss: 0.3684\n",
      "Epoch 11/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.7488 - val_loss: 0.3265\n",
      "Epoch 12/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.7021 - val_loss: 0.3091\n",
      "Epoch 13/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.6631 - val_loss: 0.2871\n",
      "Epoch 14/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.6293 - val_loss: 0.2738\n",
      "Epoch 15/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.6005 - val_loss: 0.2652\n",
      "Epoch 16/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.5757 - val_loss: 0.2535\n",
      "Epoch 17/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.5459 - val_loss: 0.2555\n",
      "Epoch 18/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.5265 - val_loss: 0.2520\n",
      "Epoch 19/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.5072 - val_loss: 0.2435\n",
      "Epoch 20/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.4854 - val_loss: 0.2403\n",
      "Epoch 21/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.4689 - val_loss: 0.2253\n",
      "Epoch 22/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.4552 - val_loss: 0.2293\n",
      "Epoch 23/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.4347 - val_loss: 0.2198\n",
      "Epoch 24/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.4199 - val_loss: 0.2159\n",
      "Epoch 25/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.4024 - val_loss: 0.2220\n",
      "Epoch 26/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.3899 - val_loss: 0.2183\n",
      "Epoch 27/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.3781 - val_loss: 0.2133\n",
      "Epoch 28/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.3652 - val_loss: 0.2198\n",
      "Epoch 29/75\n",
      "141859/141859 [==============================] - 3s 21us/step - loss: 0.3523 - val_loss: 0.2139\n",
      "Epoch 30/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.3433 - val_loss: 0.2191\n",
      "Epoch 31/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.3327 - val_loss: 0.2134\n",
      "Epoch 32/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.3217 - val_loss: 0.2069\n",
      "Epoch 33/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.3134 - val_loss: 0.2044\n",
      "Epoch 34/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.3063 - val_loss: 0.2079\n",
      "Epoch 35/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2987 - val_loss: 0.2044\n",
      "Epoch 36/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2921 - val_loss: 0.2045\n",
      "Epoch 37/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2841 - val_loss: 0.2034\n",
      "Epoch 38/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2816 - val_loss: 0.2041\n",
      "Epoch 39/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2746 - val_loss: 0.2050\n",
      "Epoch 40/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2682 - val_loss: 0.2021\n",
      "Epoch 41/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2655 - val_loss: 0.2007\n",
      "Epoch 42/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2642 - val_loss: 0.1997\n",
      "Epoch 43/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2602 - val_loss: 0.1983\n",
      "Epoch 44/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2570 - val_loss: 0.2022\n",
      "Epoch 45/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2551 - val_loss: 0.1964\n",
      "Epoch 46/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2519 - val_loss: 0.1977\n",
      "Epoch 47/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2502 - val_loss: 0.1958\n",
      "Epoch 48/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2489 - val_loss: 0.2005\n",
      "Epoch 49/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2487 - val_loss: 0.1917\n",
      "Epoch 50/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2452 - val_loss: 0.1969\n",
      "Epoch 51/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2421 - val_loss: 0.1980\n",
      "Epoch 52/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2434 - val_loss: 0.1937\n",
      "Epoch 53/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2410 - val_loss: 0.1921\n",
      "Epoch 54/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2413 - val_loss: 0.1916\n",
      "Epoch 55/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2410 - val_loss: 0.1928\n",
      "Epoch 56/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2385 - val_loss: 0.1909\n",
      "Epoch 57/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2391 - val_loss: 0.1898\n",
      "Epoch 58/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2385 - val_loss: 0.1880\n",
      "Epoch 59/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2364 - val_loss: 0.1943\n",
      "Epoch 60/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2380 - val_loss: 0.1896\n",
      "Epoch 61/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2385 - val_loss: 0.1868\n",
      "Epoch 62/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2367 - val_loss: 0.1908\n",
      "Epoch 63/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2363 - val_loss: 0.1876\n",
      "Epoch 64/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2338 - val_loss: 0.1853\n",
      "Epoch 65/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2361 - val_loss: 0.1902\n",
      "Epoch 66/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2353 - val_loss: 0.1882\n",
      "Epoch 67/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2352 - val_loss: 0.1926\n",
      "Epoch 68/75\n",
      "141859/141859 [==============================] - 3s 20us/step - loss: 0.2359 - val_loss: 0.1842\n",
      "Epoch 69/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2329 - val_loss: 0.1860\n",
      "Epoch 70/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2340 - val_loss: 0.1897\n",
      "Epoch 71/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2331 - val_loss: 0.1868\n",
      "Epoch 72/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2308 - val_loss: 0.1856\n",
      "Epoch 73/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2335 - val_loss: 0.1805\n",
      "Epoch 74/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2317 - val_loss: 0.1850\n",
      "Epoch 75/75\n",
      "141859/141859 [==============================] - 3s 19us/step - loss: 0.2297 - val_loss: 0.1806\n",
      "Building model 14 of 16\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/75\n",
      "141859/141859 [==============================] - 5s 33us/step - loss: 6.4580 - val_loss: 3.3601\n",
      "Epoch 2/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 3.3602 - val_loss: 2.3617\n",
      "Epoch 3/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 2.4523 - val_loss: 1.6884\n",
      "Epoch 4/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 1.8944 - val_loss: 1.2788\n",
      "Epoch 5/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 1.5311 - val_loss: 0.9886\n",
      "Epoch 6/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 1.2847 - val_loss: 0.7916\n",
      "Epoch 7/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 1.1108 - val_loss: 0.6697\n",
      "Epoch 8/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.9819 - val_loss: 0.5635\n",
      "Epoch 9/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.8864 - val_loss: 0.4980\n",
      "Epoch 10/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.8121 - val_loss: 0.4355\n",
      "Epoch 11/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.7488 - val_loss: 0.3964\n",
      "Epoch 12/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.7004 - val_loss: 0.3670\n",
      "Epoch 13/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.6583 - val_loss: 0.3371\n",
      "Epoch 14/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.6219 - val_loss: 0.3267\n",
      "Epoch 15/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.5946 - val_loss: 0.2982\n",
      "Epoch 16/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.5672 - val_loss: 0.2921\n",
      "Epoch 17/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.5414 - val_loss: 0.2797\n",
      "Epoch 18/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.5225 - val_loss: 0.2741\n",
      "Epoch 19/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.5033 - val_loss: 0.2675\n",
      "Epoch 20/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.4866 - val_loss: 0.2599\n",
      "Epoch 21/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.4712 - val_loss: 0.2606\n",
      "Epoch 22/75\n",
      "141859/141859 [==============================] - 4s 26us/step - loss: 0.4538 - val_loss: 0.2542\n",
      "Epoch 23/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.4405 - val_loss: 0.2488\n",
      "Epoch 24/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.4272 - val_loss: 0.2453\n",
      "Epoch 25/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.4155 - val_loss: 0.2530\n",
      "Epoch 26/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.4043 - val_loss: 0.2380\n",
      "Epoch 27/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3914 - val_loss: 0.2443\n",
      "Epoch 28/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3818 - val_loss: 0.2415\n",
      "Epoch 29/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3722 - val_loss: 0.2361\n",
      "Epoch 30/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3651 - val_loss: 0.2358\n",
      "Epoch 31/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3532 - val_loss: 0.2318\n",
      "Epoch 32/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3466 - val_loss: 0.2327\n",
      "Epoch 33/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3421 - val_loss: 0.2322\n",
      "Epoch 34/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3335 - val_loss: 0.2287\n",
      "Epoch 35/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.3288 - val_loss: 0.2260\n",
      "Epoch 36/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3223 - val_loss: 0.2268\n",
      "Epoch 37/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3167 - val_loss: 0.2245\n",
      "Epoch 38/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3153 - val_loss: 0.2310\n",
      "Epoch 39/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3102 - val_loss: 0.2257\n",
      "Epoch 40/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3054 - val_loss: 0.2290\n",
      "Epoch 41/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3057 - val_loss: 0.2228\n",
      "Epoch 42/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3013 - val_loss: 0.2335\n",
      "Epoch 43/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2986 - val_loss: 0.2318\n",
      "Epoch 44/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2980 - val_loss: 0.2227\n",
      "Epoch 45/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2932 - val_loss: 0.2235\n",
      "Epoch 46/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2895 - val_loss: 0.2281\n",
      "Epoch 47/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2873 - val_loss: 0.2298\n",
      "Epoch 48/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2878 - val_loss: 0.2215\n",
      "Epoch 49/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2841 - val_loss: 0.2209\n",
      "Epoch 50/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2860 - val_loss: 0.2267\n",
      "Epoch 51/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2850 - val_loss: 0.2168\n",
      "Epoch 52/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2876 - val_loss: 0.2248\n",
      "Epoch 53/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2847 - val_loss: 0.2174\n",
      "Epoch 54/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2847 - val_loss: 0.2251\n",
      "Epoch 55/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2862 - val_loss: 0.2140\n",
      "Epoch 56/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2826 - val_loss: 0.2198\n",
      "Epoch 57/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2852 - val_loss: 0.2180\n",
      "Epoch 58/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2820 - val_loss: 0.2260\n",
      "Epoch 59/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2841 - val_loss: 0.2197\n",
      "Epoch 60/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2835 - val_loss: 0.2159\n",
      "Epoch 61/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2837 - val_loss: 0.2166\n",
      "Epoch 62/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2814 - val_loss: 0.2168\n",
      "Building model 15 of 16\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/75\n",
      "141859/141859 [==============================] - 5s 34us/step - loss: 7.1619 - val_loss: 3.3595\n",
      "Epoch 2/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 3.7260 - val_loss: 2.4284\n",
      "Epoch 3/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 2.8718 - val_loss: 1.9057\n",
      "Epoch 4/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 2.2982 - val_loss: 1.5202\n",
      "Epoch 5/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 1.9013 - val_loss: 1.2343\n",
      "Epoch 6/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 1.5968 - val_loss: 1.0245\n",
      "Epoch 7/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 1.3747 - val_loss: 0.8466\n",
      "Epoch 8/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 1.2042 - val_loss: 0.7112\n",
      "Epoch 9/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 1.0753 - val_loss: 0.6213\n",
      "Epoch 10/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.9763 - val_loss: 0.5449\n",
      "Epoch 11/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.8905 - val_loss: 0.4907\n",
      "Epoch 12/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.8198 - val_loss: 0.4346\n",
      "Epoch 13/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.7577 - val_loss: 0.3977\n",
      "Epoch 14/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.7165 - val_loss: 0.3752\n",
      "Epoch 15/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.6702 - val_loss: 0.3414\n",
      "Epoch 16/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.6415 - val_loss: 0.3238\n",
      "Epoch 17/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.6087 - val_loss: 0.3165\n",
      "Epoch 18/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.5773 - val_loss: 0.2925\n",
      "Epoch 19/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.5556 - val_loss: 0.2849\n",
      "Epoch 20/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.5284 - val_loss: 0.2865\n",
      "Epoch 21/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.5076 - val_loss: 0.2649\n",
      "Epoch 22/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.4917 - val_loss: 0.2644\n",
      "Epoch 23/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.4681 - val_loss: 0.2504\n",
      "Epoch 24/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.4531 - val_loss: 0.2515\n",
      "Epoch 25/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.4360 - val_loss: 0.2395\n",
      "Epoch 26/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.4194 - val_loss: 0.2368\n",
      "Epoch 27/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.4077 - val_loss: 0.2349\n",
      "Epoch 28/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.3937 - val_loss: 0.2342\n",
      "Epoch 29/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3813 - val_loss: 0.2308\n",
      "Epoch 30/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3692 - val_loss: 0.2232\n",
      "Epoch 31/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3588 - val_loss: 0.2255\n",
      "Epoch 32/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3471 - val_loss: 0.2205\n",
      "Epoch 33/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3369 - val_loss: 0.2163\n",
      "Epoch 34/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3302 - val_loss: 0.2204\n",
      "Epoch 35/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.3206 - val_loss: 0.2207\n",
      "Epoch 36/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3168 - val_loss: 0.2127\n",
      "Epoch 37/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.3045 - val_loss: 0.2090\n",
      "Epoch 38/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2979 - val_loss: 0.2111\n",
      "Epoch 39/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2932 - val_loss: 0.2123\n",
      "Epoch 40/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2869 - val_loss: 0.2104\n",
      "Epoch 41/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2805 - val_loss: 0.2068\n",
      "Epoch 42/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2732 - val_loss: 0.2049\n",
      "Epoch 43/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2712 - val_loss: 0.2018\n",
      "Epoch 44/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2655 - val_loss: 0.2040\n",
      "Epoch 45/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2637 - val_loss: 0.2004\n",
      "Epoch 46/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2587 - val_loss: 0.2011\n",
      "Epoch 47/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2585 - val_loss: 0.1998\n",
      "Epoch 48/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2566 - val_loss: 0.1966\n",
      "Epoch 49/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2525 - val_loss: 0.2062\n",
      "Epoch 50/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2536 - val_loss: 0.1977\n",
      "Epoch 51/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2490 - val_loss: 0.1953\n",
      "Epoch 52/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2468 - val_loss: 0.1987\n",
      "Epoch 53/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2450 - val_loss: 0.1912\n",
      "Epoch 54/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2428 - val_loss: 0.1992\n",
      "Epoch 55/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2430 - val_loss: 0.1895\n",
      "Epoch 56/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2406 - val_loss: 0.1890\n",
      "Epoch 57/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2391 - val_loss: 0.1879\n",
      "Epoch 58/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2381 - val_loss: 0.2010\n",
      "Epoch 59/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2407 - val_loss: 0.1874\n",
      "Epoch 60/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2381 - val_loss: 0.1920\n",
      "Epoch 61/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2379 - val_loss: 0.1911\n",
      "Epoch 62/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2399 - val_loss: 0.1894\n",
      "Epoch 63/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2352 - val_loss: 0.1933\n",
      "Epoch 64/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2365 - val_loss: 0.1895\n",
      "Epoch 65/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2357 - val_loss: 0.1873\n",
      "Epoch 66/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2334 - val_loss: 0.1906\n",
      "Epoch 67/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2351 - val_loss: 0.1834\n",
      "Epoch 68/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2344 - val_loss: 0.1847\n",
      "Epoch 69/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2321 - val_loss: 0.1838\n",
      "Epoch 70/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2335 - val_loss: 0.1941\n",
      "Epoch 71/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2328 - val_loss: 0.1844\n",
      "Epoch 72/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2308 - val_loss: 0.1841\n",
      "Epoch 73/75\n",
      "141859/141859 [==============================] - 3s 22us/step - loss: 0.2295 - val_loss: 0.1865\n",
      "Epoch 74/75\n",
      "141859/141859 [==============================] - 3s 23us/step - loss: 0.2309 - val_loss: 0.1904\n",
      "Building model 16 of 16\n",
      "Train on 141859 samples, validate on 47287 samples\n",
      "Epoch 1/75\n",
      "141859/141859 [==============================] - 5s 36us/step - loss: 7.5231 - val_loss: 3.9670\n",
      "Epoch 2/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 4.1169 - val_loss: 2.8098\n",
      "Epoch 3/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 3.0626 - val_loss: 2.0849\n",
      "Epoch 4/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 2.3850 - val_loss: 1.6040\n",
      "Epoch 5/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 1.9136 - val_loss: 1.2691\n",
      "Epoch 6/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 1.5967 - val_loss: 1.0447\n",
      "Epoch 7/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 1.3615 - val_loss: 0.8523\n",
      "Epoch 8/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 1.1869 - val_loss: 0.7226\n",
      "Epoch 9/75\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 1.0488 - val_loss: 0.6309\n",
      "Epoch 10/75\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 0.9480 - val_loss: 0.5508\n",
      "Epoch 11/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.8591 - val_loss: 0.4813\n",
      "Epoch 12/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.7933 - val_loss: 0.4422\n",
      "Epoch 13/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.7348 - val_loss: 0.4155\n",
      "Epoch 14/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.6912 - val_loss: 0.3769\n",
      "Epoch 15/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.6525 - val_loss: 0.3514\n",
      "Epoch 16/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.6193 - val_loss: 0.3320\n",
      "Epoch 17/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.5907 - val_loss: 0.3136\n",
      "Epoch 18/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.5685 - val_loss: 0.3107\n",
      "Epoch 19/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.5488 - val_loss: 0.2960\n",
      "Epoch 20/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.5257 - val_loss: 0.2879\n",
      "Epoch 21/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.5063 - val_loss: 0.2833\n",
      "Epoch 22/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.4941 - val_loss: 0.2817\n",
      "Epoch 23/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.4801 - val_loss: 0.2718\n",
      "Epoch 24/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.4683 - val_loss: 0.2702\n",
      "Epoch 25/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.4518 - val_loss: 0.2614\n",
      "Epoch 26/75\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 0.4415 - val_loss: 0.2605\n",
      "Epoch 27/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.4278 - val_loss: 0.2596\n",
      "Epoch 28/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.4177 - val_loss: 0.2585\n",
      "Epoch 29/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.4100 - val_loss: 0.2537\n",
      "Epoch 30/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.4002 - val_loss: 0.2578\n",
      "Epoch 31/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.3910 - val_loss: 0.2482\n",
      "Epoch 32/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.3823 - val_loss: 0.2487\n",
      "Epoch 33/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.3747 - val_loss: 0.2434\n",
      "Epoch 34/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.3691 - val_loss: 0.2562\n",
      "Epoch 35/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.3620 - val_loss: 0.2495\n",
      "Epoch 36/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.3563 - val_loss: 0.2414\n",
      "Epoch 37/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.3458 - val_loss: 0.2456\n",
      "Epoch 38/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.3454 - val_loss: 0.2480\n",
      "Epoch 39/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.3409 - val_loss: 0.2449\n",
      "Epoch 40/75\n",
      "141859/141859 [==============================] - 3s 25us/step - loss: 0.3350 - val_loss: 0.2449\n",
      "Epoch 41/75\n",
      "141859/141859 [==============================] - 3s 25us/step - loss: 0.3310 - val_loss: 0.2415\n",
      "Epoch 42/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.3280 - val_loss: 0.2395\n",
      "Epoch 43/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.3248 - val_loss: 0.2417\n",
      "Epoch 44/75\n",
      "141859/141859 [==============================] - 4s 25us/step - loss: 0.3205 - val_loss: 0.2362\n",
      "Epoch 45/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.3162 - val_loss: 0.2420\n",
      "Epoch 46/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.3142 - val_loss: 0.2355\n",
      "Epoch 47/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.3128 - val_loss: 0.2396\n",
      "Epoch 48/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.3132 - val_loss: 0.2469\n",
      "Epoch 49/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.3087 - val_loss: 0.2370\n",
      "Epoch 50/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.3035 - val_loss: 0.2303\n",
      "Epoch 51/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.3029 - val_loss: 0.2303\n",
      "Epoch 52/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.3034 - val_loss: 0.2295\n",
      "Epoch 53/75\n",
      "141859/141859 [==============================] - 4s 26us/step - loss: 0.3036 - val_loss: 0.2391\n",
      "Epoch 54/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.3036 - val_loss: 0.2342\n",
      "Epoch 55/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.3037 - val_loss: 0.2388\n",
      "Epoch 56/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.3082 - val_loss: 0.2350\n",
      "Epoch 57/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.3025 - val_loss: 0.2377\n",
      "Epoch 58/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.3014 - val_loss: 0.2269\n",
      "Epoch 59/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.3037 - val_loss: 0.2290\n",
      "Epoch 60/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.3000 - val_loss: 0.2292\n",
      "Epoch 61/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2967 - val_loss: 0.2283\n",
      "Epoch 62/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2979 - val_loss: 0.2310\n",
      "Epoch 63/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2998 - val_loss: 0.2306\n",
      "Epoch 64/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2948 - val_loss: 0.2268\n",
      "Epoch 65/75\n",
      "141859/141859 [==============================] - 3s 24us/step - loss: 0.2961 - val_loss: 0.2323\n"
     ]
    }
   ],
   "source": [
    "###   DO NOT RE-RUN    ###\n",
    "###   W/O NEW PARAMS   ###\n",
    "\n",
    "# final_nn_model_dict = nn_grid_search(X, y, grid_params=pdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the grid search has completed, we want to once again pickle the resulting model so we don't have to run the cell multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_model': <keras.engine.sequential.Sequential at 0x1a3361db90>,\n",
       " 'best_score': 0.8979889947307514,\n",
       " 'best_params': {'first_layer_nodes': 256,\n",
       "  'first_dropout_rate': 0,\n",
       "  'second_layer_nodes': 128,\n",
       "  'second_dropout_rate': 0,\n",
       "  'third_layer_nodes': 64,\n",
       "  'third_dropout_rate': 0,\n",
       "  'reg': 0.001,\n",
       "  'epochs': 75,\n",
       "  'early_stop': <keras.callbacks.EarlyStopping at 0x1a3361df90>},\n",
       " 'best_history': <keras.callbacks.History at 0x1a336bfa90>,\n",
       " 'test_preds': array([[5.361496 ],\n",
       "        [4.5653467],\n",
       "        [3.9581513],\n",
       "        ...,\n",
       "        [4.8386326],\n",
       "        [4.725911 ],\n",
       "        [3.547521 ]], dtype=float32)}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_nn_model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "###   DO NOT RE-RUN    ###\n",
    "###   W/O ABOVE CELL   ###\n",
    "\n",
    "# # making new file\n",
    "# outfile = open(\"final_nn_pickle\", \"wb\")\n",
    "\n",
    "# # dumping model to pickle\n",
    "# pickle.dump(final_nn_model_dict, outfile)\n",
    "\n",
    "# # closing new file\n",
    "# outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jondov/anaconda3/envs/dsi/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jondov/anaconda3/envs/dsi/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jondov/anaconda3/envs/dsi/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jondov/anaconda3/envs/dsi/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# opening pickle file\n",
    "infile = open(\"final_nn_pickle\", \"rb\")\n",
    "\n",
    "# unpickling back into model object\n",
    "final_nn_model_dict = pickle.load(infile)\n",
    "\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train R2 score is: 0.9023666954449441.\n",
      "The test R2 score is: 0.8979889947307514.\n"
     ]
    }
   ],
   "source": [
    "# saving final model as it's own object\n",
    "final_nn_model = final_nn_model_dict[\"best_model\"]\n",
    "\n",
    "# making predictions\n",
    "nn_train_preds = final_nn_model.predict(X_train_sc)\n",
    "nn_test_preds = final_nn_model.predict(X_test_sc)\n",
    "\n",
    "# checking r2\n",
    "print(f\"The train R2 score is: {metrics.r2_score(y_train, nn_train_preds)}.\")\n",
    "print(f\"The test R2 score is: {metrics.r2_score(y_test, nn_test_preds)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This appears to have given use the best scores out of all the models. Before making any conclusions, though, we are going to compile all of the results and see the metrics together to make the final call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help automate the eavluations process, we are going to compile the train and test predictions for each of our models, and from there we will be able to easily evaluate the desired metrics from one spot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making train pred df\n",
    "train_pred_df = pd.DataFrame(columns=[\"y_train\",\n",
    "                                      \"base\",\n",
    "                                      \"linear\",\n",
    "                                      \"lasso\",\n",
    "                                      \"ridge\",\n",
    "                                      \"neural_net\"])\n",
    "\n",
    "# making test pred df\n",
    "test_pred_df = pd.DataFrame(columns=[\"y_test\",\n",
    "                                     \"base\",\n",
    "                                     \"linear\",\n",
    "                                     \"lasso\",\n",
    "                                     \"ridge\",\n",
    "                                     \"neural_net\"])\n",
    "# filling both y_true cols\n",
    "train_pred_df[\"y_train\"] = np.exp(y_train)\n",
    "test_pred_df[\"y_test\"] = np.exp(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making dicts of our models\n",
    "# one for unscaled Xs\n",
    "unsc_models = {\"base\": base_mean_model,\n",
    "               \"linear\": linreg_model}\n",
    "\n",
    "# one for scaled Xs\n",
    "sc_models = {\"lasso\": lasso_model,\n",
    "             \"ridge\": ridge_model,\n",
    "             \"neural_net\": final_nn_model}\n",
    "\n",
    "\n",
    "# looping through unsc_models to input preds into df\n",
    "for model in unsc_models.keys():\n",
    "    train_pred_df[model] = np.exp(unsc_models[model].predict(X_train))\n",
    "    test_pred_df[model] = np.exp(unsc_models[model].predict(X_test))\n",
    "\n",
    "# looping through sc_models to input preds into df\n",
    "for model in sc_models.keys():\n",
    "    train_pred_df[model] = np.exp(sc_models[model].predict(X_train_sc))\n",
    "    test_pred_df[model] = np.exp(sc_models[model].predict(X_test_sc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_train</th>\n",
       "      <th>base</th>\n",
       "      <th>linear</th>\n",
       "      <th>lasso</th>\n",
       "      <th>ridge</th>\n",
       "      <th>neural_net</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147647</th>\n",
       "      <td>56.0</td>\n",
       "      <td>43.234931</td>\n",
       "      <td>44.004832</td>\n",
       "      <td>40.832121</td>\n",
       "      <td>44.003356</td>\n",
       "      <td>26.068771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109815</th>\n",
       "      <td>52.0</td>\n",
       "      <td>43.234931</td>\n",
       "      <td>53.521408</td>\n",
       "      <td>53.234836</td>\n",
       "      <td>53.525497</td>\n",
       "      <td>51.870228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141021</th>\n",
       "      <td>28.0</td>\n",
       "      <td>43.234931</td>\n",
       "      <td>26.400813</td>\n",
       "      <td>26.655251</td>\n",
       "      <td>26.402932</td>\n",
       "      <td>30.008564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110050</th>\n",
       "      <td>60.0</td>\n",
       "      <td>43.234931</td>\n",
       "      <td>60.934555</td>\n",
       "      <td>60.084064</td>\n",
       "      <td>60.906349</td>\n",
       "      <td>46.401402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163510</th>\n",
       "      <td>247.0</td>\n",
       "      <td>43.234931</td>\n",
       "      <td>175.687923</td>\n",
       "      <td>174.521025</td>\n",
       "      <td>175.667826</td>\n",
       "      <td>257.309235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        y_train       base      linear       lasso       ridge  neural_net\n",
       "147647     56.0  43.234931   44.004832   40.832121   44.003356   26.068771\n",
       "109815     52.0  43.234931   53.521408   53.234836   53.525497   51.870228\n",
       "141021     28.0  43.234931   26.400813   26.655251   26.402932   30.008564\n",
       "110050     60.0  43.234931   60.934555   60.084064   60.906349   46.401402\n",
       "163510    247.0  43.234931  175.687923  174.521025  175.667826  257.309235"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>base</th>\n",
       "      <th>linear</th>\n",
       "      <th>lasso</th>\n",
       "      <th>ridge</th>\n",
       "      <th>neural_net</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88488</th>\n",
       "      <td>245.0</td>\n",
       "      <td>43.234931</td>\n",
       "      <td>133.968872</td>\n",
       "      <td>133.823287</td>\n",
       "      <td>133.919194</td>\n",
       "      <td>291.741333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179653</th>\n",
       "      <td>91.0</td>\n",
       "      <td>43.234931</td>\n",
       "      <td>93.642083</td>\n",
       "      <td>93.202277</td>\n",
       "      <td>93.628761</td>\n",
       "      <td>90.791046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169634</th>\n",
       "      <td>45.0</td>\n",
       "      <td>43.234931</td>\n",
       "      <td>46.437591</td>\n",
       "      <td>46.216515</td>\n",
       "      <td>46.437398</td>\n",
       "      <td>47.342304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45499</th>\n",
       "      <td>21.0</td>\n",
       "      <td>43.234931</td>\n",
       "      <td>25.529767</td>\n",
       "      <td>25.716819</td>\n",
       "      <td>25.542199</td>\n",
       "      <td>25.163540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113786</th>\n",
       "      <td>25.0</td>\n",
       "      <td>43.234931</td>\n",
       "      <td>25.680915</td>\n",
       "      <td>25.799408</td>\n",
       "      <td>25.691698</td>\n",
       "      <td>27.399517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        y_test       base      linear       lasso       ridge  neural_net\n",
       "88488    245.0  43.234931  133.968872  133.823287  133.919194  291.741333\n",
       "179653    91.0  43.234931   93.642083   93.202277   93.628761   90.791046\n",
       "169634    45.0  43.234931   46.437591   46.216515   46.437398   47.342304\n",
       "45499     21.0  43.234931   25.529767   25.716819   25.542199   25.163540\n",
       "113786    25.0  43.234931   25.680915   25.799408   25.691698   27.399517"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R<sup>2</sup> Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate the R<sup>2</sup> scores to determine how much of the variation in the serving sizes can be explained by our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making r2 dataframe\n",
    "r2_df = pd.DataFrame(index=train_pred_df.columns[1:], columns=[\"train_r2\", \"test_r2\"])\n",
    "\n",
    "# looping through models\n",
    "for model in train_pred_df.columns[1:]:\n",
    "    \n",
    "    # setting the scores for the model row\n",
    "    r2_df.loc[model] = [\n",
    "        round(100 * metrics.r2_score(train_pred_df[\"y_train\"], train_pred_df[model]), 2),\n",
    "        round(100 * metrics.r2_score(test_pred_df[\"y_test\"], test_pred_df[model]), 2)\n",
    "    ]\n",
    "    \n",
    "# making variance column\n",
    "r2_df[\"var\"] = abs(r2_df[\"train_r2\"] - r2_df[\"test_r2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_r2</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>base</th>\n",
       "      <td>-12.78</td>\n",
       "      <td>-13.27</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear</th>\n",
       "      <td>69.2</td>\n",
       "      <td>68.48</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasso</th>\n",
       "      <td>69.19</td>\n",
       "      <td>68.44</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge</th>\n",
       "      <td>69.2</td>\n",
       "      <td>68.48</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neural_net</th>\n",
       "      <td>81.78</td>\n",
       "      <td>80.31</td>\n",
       "      <td>1.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           train_r2 test_r2   var\n",
       "base         -12.78  -13.27  0.49\n",
       "linear         69.2   68.48  0.72\n",
       "lasso         69.19   68.44  0.75\n",
       "ridge          69.2   68.48  0.72\n",
       "neural_net    81.78   80.31  1.47"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pulling up final df\n",
    "r2_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see in this dataframe why the MSE was used as the scoring method for the original baseline model. Due to the intricacies of this regression problem, and the large amount of features being used, the mean prediction results in a negative score here. In other words, using the mean serving size is a very bad predictor. Since we translated our predictions from the logged-serving size back to the real serving size, we appear to have dropped our scores a bit. This is unfortunate, but not completely unexpected, as exponentiating the numbers puts them on a much larger scale, so the errors are going to be magnified. However, the FFNN has maintained its leading score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean squared error can sometimes be a better scoring method than R<sup>2</sup>, since it is a direct measure of how far off the predictions are from the true y-values. Since we previously saw the MSE from the base model, we should compare that with our improved model types as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making r2 dataframe\n",
    "mse_df = pd.DataFrame(index=train_pred_df.columns[1:], columns=[\"train_mse\", \"test_mse\"])\n",
    "\n",
    "# looping through models\n",
    "for model in train_pred_df.columns[1:]:\n",
    "    \n",
    "    # setting the scores for the model row\n",
    "    mse_df.loc[model] = [\n",
    "        metrics.mean_squared_error(train_pred_df[\"y_train\"], train_pred_df[model]),\n",
    "        metrics.mean_squared_error(test_pred_df[\"y_test\"], test_pred_df[model])\n",
    "    ]\n",
    "\n",
    "# making variance column\n",
    "mse_df[\"var\"] = abs(mse_df[\"train_mse\"] - mse_df[\"test_mse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_mse</th>\n",
       "      <th>test_mse</th>\n",
       "      <th>var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>base</th>\n",
       "      <td>3685.34</td>\n",
       "      <td>3833.12</td>\n",
       "      <td>147.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear</th>\n",
       "      <td>1006.6</td>\n",
       "      <td>1066.49</td>\n",
       "      <td>59.8882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasso</th>\n",
       "      <td>1006.72</td>\n",
       "      <td>1067.95</td>\n",
       "      <td>61.2309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge</th>\n",
       "      <td>1006.64</td>\n",
       "      <td>1066.57</td>\n",
       "      <td>59.9296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neural_net</th>\n",
       "      <td>595.368</td>\n",
       "      <td>666.202</td>\n",
       "      <td>70.8335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           train_mse test_mse      var\n",
       "base         3685.34  3833.12  147.779\n",
       "linear        1006.6  1066.49  59.8882\n",
       "lasso        1006.72  1067.95  61.2309\n",
       "ridge        1006.64  1066.57  59.9296\n",
       "neural_net   595.368  666.202  70.8335"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pulling up final df\n",
    "mse_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from these numbers that the neural network had by far the lowest MSE scores, though it was somewhat more overfit than the others , showing the highest variance number (excluding the baseline \"model\"). However, due to how much better of a performance it was able to give us, we are going to select that as our final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = final_nn_model_dict[\"best_history\"].history[\"loss\"]\n",
    "test_loss = final_nn_model_dict[\"best_history\"].history[\"val_loss\"]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(train_loss, label='Training loss', color='navy')\n",
    "plt.plot(test_loss, label='Testing loss', color='orange')\n",
    "plt.title(\"Loss Curve of Best Neural Network\", size=20)\n",
    "plt.xlabel(\"Epoch\", size=15)\n",
    "plt.ylabel(\"Loss\", size=15)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line graph shows us how the loss of our final model changed as it ran through 50 epochs. There does not appear to be a lot of variation in the curves, and we have avoided significant divergence of the losses between the train and test set, though the test loss does tick up slightly at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from this comparison of predicted and actual serving sizes that our model has a clear tendency to underpredict servings as the real serving size increases. There could be several reasons behind why this is happening, though one clear and logical answer may be that some of those foods with larger serving sizes have larger portions of the food that are inedible. This could mean a food that has shells or pits, or something else that is counted in the total weight, but is not eaten. This is most likely where the outliers are arising from. Unfortunately, these aspects were not accounted for in this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# finding residuals\n",
    "resids = test_pred_df[\"y_test\"] - test_pred_df[\"neural_net\"]\n",
    "\n",
    "# making plot of resids vs. preds\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.scatterplot(test_pred_df[\"neural_net\"], resids)\n",
    "plt.title(\"Homoskedasticity of Residals\", size=20)\n",
    "plt.xlabel(\"Predicted Log-Serving Size\", size=14)\n",
    "plt.ylabel(\"Residual from True Log-Serving Size\", size=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows that the residuals from the model are fairly homoscedastic, with only a few outliers. There could be several reasons behind the placement of these outliers, though one clear and logical answer may be that some of those foods with larger serving sizes have larger portions of the food that are inedible. This could mean a food that has shells or pits, or something else that is counted in the total weight, but is not eaten. This is most likely where the outliers are arising from. Unfortunately, these aspects were not accounted for in this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "sns.distplot(resids, bins=20, kde=False)\n",
    "plt.title(\"Normal Distribution of Residuals\", size=20)\n",
    "plt.xlabel(\"Deviation from True Log-Serving Size\", size=15)\n",
    "plt.ylabel(\"Frequency of Distance\", size=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from this histogram that the residuals form a normally shaped distrubition, albeit with a long right tail. Coupled with the scatterplot above, We can conclude that we have made a well fit model with no clear trends in the errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizing a feed forward neural network gave use the best results overall. It was able to increase the R<sup>2</sup> score above 80%, and still limit difference between the train and test sets to below 1.5%. It was also able to minimize MSE far better than the other models that were made. However, this model was still not perfect, and there are still outliers in the residuals. \n",
    "\n",
    "As discussed above, this may be influenced by factors unseen by the model, such as the percentage of the food item that is not typically eaten. In addition, this model only takes certain attributes into account, and there are many other factors that can have an impact on serving size, such as package size, sale price, or targeted demographic. Many of these factors can be proprietary information to the manufacturing company, and are unavailable to the public, making a deeper analysis difficult. This could, however, be adapted within a specific company to account for some of these features, or to be trained on a more specific set of foods products.\n",
    "\n",
    "In the end, this model should still be fairly useful to a project team that is working to develop a new food product. If the standard nutrition facts and category can be enterered, the resulting serving size should be fairly close to similar products on the market in that category, and can be useful in the development process. This way, researchers have a good idea of what their final servings size might be, and can have a head start on things like branding and marketing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the main recommendations for this project would be to conduct further analysis of the vectorized ingredients. Utilizing the ingredients as features did not appear to help our models in the current scope, though with more time to optimize, they may be able to improve the model further. A more complex method of cleaning and vectorizing this feature may allow it to be more effectively be incorporated into the model. As ingredients lists are always in order of largest to smallest amounts, it may be possible to use some kind of weight attribute on ingredients to show theimpact of that ingredient of the food's nutrition and serving size. Further use of NLP could also be used to analyze the food descriptions or brand owners as well.\n",
    "\n",
    "Another interesting step to take would be to perform PCA on the nutrient features. This would be able to definitively eliminate any possibility of multicolinearity in the X variables. It would also ensure that only the most valuable elements of each of the features were being effectively used to make the prediction.\n",
    "\n",
    "Further utilization of the neural network grid search function. The project timeline and available computing power were severe limits on fully fleshing out the neural network. Of course the possibilities are truly endless, but even within the scope of layers, nodes, and regularization that were searched through here, there is most likely further optimization that could be done.\n",
    "\n",
    "Another modeling option could be to use a support vector machine (SVM), as this may be a more fitting model for this type of data. Unfortunately, due to the large amount of data and features being used, there was once again a computing power issue preventing this type of model from being run. It may also be possible to use a decision tree-based regressor model on this data.\n",
    "\n",
    "Overall, the computational issues in this project could possibly be overcome by utilizing cloud computing services, such as those available on Amazon Web Services, or perhaps even just using a more powerful home computer.\n",
    "\n",
    "The last recommendation would be to continually maintain the dataset, as the USDA periodically updates the information stored in it. This could entail downloading the zip file when a new version comes out, or it could be linked to the API access port to continually update."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi] *",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
